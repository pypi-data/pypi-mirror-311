{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook loads the crosscoders by Julian Minder and Cl√©ment Dumas and uploads them to Neuronpedia.\n",
    "### This also uploads the activations associated with each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "\n",
    "NUM_FEATURES_TO_UPLOAD = 10\n",
    "LAYER_NUM = 13\n",
    "\n",
    "print(\"downloading max activating examples from huggingface, load the top ones sorted by base uselessness score\")\n",
    "repo_id = \"Butanium/max-activating-examples-gemma-2-2b-l13-mu4.1e-02-lr1e-04\"\n",
    "df_path = hf_hub_download(repo_id=repo_id, filename=\"feature_df.csv\", repo_type=\"dataset\")\n",
    "\n",
    "df = pd.read_csv(df_path, index_col=0)\n",
    "available_features = df[(df[\"tag\"].isin([\"IT only\", \"Base only\"])) & (df[\"dead\"] == False)]\n",
    "available_features_idx = available_features.index.tolist()\n",
    "\n",
    "filtered_features = available_features.sort_values(by=\"base uselessness score\", ascending=False).head(\n",
    "    NUM_FEATURES_TO_UPLOAD\n",
    ")\n",
    "available_features_idx = filtered_features.index.tolist()\n",
    "print(len(available_features_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max act examples db and tokenizer\n",
    "from tiny_dashboard import OfflineFeatureCentricDashboard\n",
    "from nnterp import load_model\n",
    "import gc\n",
    "\n",
    "gemma_2_it = load_model(\"google/gemma-2-2b-it\", device_map=\"cuda\")\n",
    "db_path = hf_hub_download(repo_id=repo_id, filename=\"chat_base_examples_20.db\", repo_type=\"dataset\")\n",
    "gc.collect()\n",
    "db = OfflineFeatureCentricDashboard.from_db(db_path, gemma_2_it.tokenizer, column_name=\"entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the crosscoders\n",
    "from neuronpedia.butanium_dictionary_learning.dictionary_learning import CrossCoder\n",
    "\n",
    "print(\"getting the crosscoders\")\n",
    "crosscoder = CrossCoder.from_pretrained(\"Butanium/gemma-2-2b-crosscoder-l13-mu4.1e-02-lr1e-04\", from_hub=True)\n",
    "print(\"got the crosscoders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronpedia.np_vector import NPVector\n",
    "from neuronpedia.requests.activation_request import Activation\n",
    "\n",
    "counter = 0\n",
    "created_np_vectors = []\n",
    "for feature_idx in available_features_idx:\n",
    "    counter += 1\n",
    "\n",
    "    print(\"Uploading vector for feature\", feature_idx)\n",
    "    print(\"Progress:\", counter, \"/\", len(available_features_idx))\n",
    "\n",
    "    # get the weights from the crosscoder and upload it\n",
    "    crosscoder_weight = crosscoder.encoder.weight[1][:, feature_idx].detach().tolist()\n",
    "\n",
    "    print(\"Uploading vector for feature\", feature_idx)\n",
    "    np_vector = NPVector.new(\n",
    "        label=\"Crosscoder L13 \" + str(feature_idx) + \" Dumas/Minder\",\n",
    "        model_id=\"gemma-2-2b-it\",\n",
    "        layer_num=LAYER_NUM,\n",
    "        hook_type=\"hook_resid_pre\",\n",
    "        vector=crosscoder_weight,\n",
    "        default_steer_strength=20,\n",
    "    )\n",
    "    created_np_vectors.append(np_vector)\n",
    "    # get the associated activations and upload them\n",
    "    featActs = db.max_activation_examples[feature_idx]\n",
    "    activationsToUpload: list[Activation] = []\n",
    "    for act in featActs:\n",
    "        max_activation_value, tokens, activation_values = act\n",
    "        activation = Activation(\n",
    "            tokens=tokens,\n",
    "            values=activation_values,\n",
    "        )\n",
    "        activationsToUpload.append(activation)\n",
    "    print(\"Uploading activations for feature\", feature_idx)\n",
    "    np_vector.upload_activations(activationsToUpload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronpedia.np_list import NPList, NPListItem\n",
    "from neuronpedia.np_vector import NPVector\n",
    "import webbrowser\n",
    "\n",
    "# create a new list\n",
    "new_list = NPList.new(\"Crosscoder L13 Dumas/Minder\")\n",
    "print(new_list)\n",
    "new_list_url = \"https://neuronpedia.org/list/\" + new_list.id\n",
    "print(new_list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn created np vectors into listitems\n",
    "list_items = [\n",
    "    NPListItem(\n",
    "        model_id=vector.model_id, source=vector.source, index=vector.index, description=f\"Crosscoder L13 {vector.index}\"\n",
    "    )\n",
    "    for vector in created_np_vectors\n",
    "]\n",
    "\n",
    "# batch it up into 100 items at a time for upload\n",
    "batches = [list_items[i : i + 100] for i in range(0, len(list_items), 100)]\n",
    "\n",
    "# do the upload\n",
    "for batch in batches:\n",
    "    print(batch[0])\n",
    "    print(\"Adding batch of\", len(batch), \"items to the list\")\n",
    "    new_list.add_items(batch)\n",
    "\n",
    "# print(new_list_url)\n",
    "\n",
    "webbrowser.open(new_list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_list = NPList.get(new_list.id)\n",
    "print(np_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
