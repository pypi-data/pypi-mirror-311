Metadata-Version: 2.1
Name: promptscan-sdk
Version: 0.1.1
Author-Email: Bogdan Sulima <bogdan.sulima@promptscan.ai>
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Project-URL: Homepage, https://github.com/promptscan/sdk-python
Project-URL: Issues, https://github.com/promptscan/sdk-python/issues
Requires-Python: >=3.9
Requires-Dist: pydantic>=2
Requires-Dist: python-dateutil==2.9.0
Requires-Dist: httpx<1.0,>=0.27
Provides-Extra: test
Requires-Dist: pytest==8.3.1; extra == "test"
Requires-Dist: pytest-asyncio==0.23.8; extra == "test"
Requires-Dist: pytest-dotenv==0.5.2; extra == "test"
Requires-Dist: pytest-recording==0.13.2; extra == "test"
Requires-Dist: pytest-sugar==1.0.0; extra == "test"
Requires-Dist: vcrpy==6.0.1; extra == "test"
Requires-Dist: openai==1.55.1; extra == "test"
Provides-Extra: dev
Requires-Dist: ariadne-codegen==0.14.0; extra == "dev"
Description-Content-Type: text/markdown

# PromptScan Python SDK

The PromptScan Python SDK provides a simple way to integrate PromptScan's monitoring and analytics capabilities into your LLM application.

## Installation

```bash
pip install promptscan-sdk
```

## Quick Start

```python
import promptscan_sdk
from promptscan_sdk.client import GenerationInput, GenerationMessageInput, UsageInput
from datetime import datetime, UTC

# Initialize the SDK
promptscan_sdk.configure(api_key="your-project-api-key")

# Collect generation data
promptscan_sdk.collect(
    GenerationInput(
        session_id="unique-session-id",
        id="generation-id",
        model="gpt-4",
        messages=[
            GenerationMessageInput(role="system", content="You are a helpful assistant.")
        ],
        usage=UsageInput(
            prompt_tokens=100,
            completion_tokens=50,
            total_tokens=150
        ),
        created=datetime.now(tz=UTC),
        duration=0.5,
        time_to_first_token=0.15
    )
)

# Close the SDK on application exit, since it uses background threads for non-blocking flushing of the generations that should be stopped and generation buffer flushed.
promptscan_sdk.close()
```

## Multiple api-key support

You can log generations for different projects by using multiple project api-keys.

```python
collect(generation_a_input, api_key="your-project-A-api-key")
collect(generation_b_input, api_key="your-project-B-api-key")
```


[//]: # (## OpenAI API)

[//]: # ()
[//]: # (```python)

[//]: # (from promptscan_sdk.utils import from_openai_completion)

[//]: # ()
[//]: # (generation = from_openai_completion&#40;completion&#41;)

[//]: # (collect&#40;generation&#41;)

[//]: # (```)

[//]: # ()
[//]: # (```python)

[//]: # (from promptscan_sdk.utils import from_openai_completion)

[//]: # ()
[//]: # (generation, chunks = from_openai_completion_stream&#40;completion&#41;)

[//]: # ()
[//]: # (for chunk in chunks:)

[//]: # (    pass)

[//]: # ()
[//]: # (collect&#40;generation&#41;)

[//]: # (```)