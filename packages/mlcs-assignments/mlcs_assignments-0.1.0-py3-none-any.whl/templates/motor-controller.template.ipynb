{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254f18db",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "You can run the following cell to install all the libraries we'll be using throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c113e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy sympy scipy pandas plotly ipywidgets scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d3726",
   "metadata": {},
   "source": [
    "# Controlling an Overheating Motor with Gaussian Process Regression\n",
    "\n",
    "## 1. Introduction to the Motor\n",
    "\n",
    "In this assignment, we will implement a bang-bang controller to regulate the activity of a motor, such that it works as fast as possible without overheating. As usual,\n",
    "before we go into the details of the controller, let's first understand the motor and how it operates.\n",
    "\n",
    "### 1.1 Motor Dynamics\n",
    "\n",
    "The motor we are working with is a simple DC motor. The motor is controlled by an electric current $u(t)$, which determines the angular velocity of the motor $\\omega(t)$. \n",
    "The motor is subject to a load torque $T_L(t)$, which is the some kind of external resistance applied to the motor. The motor dynamics are described by the following \n",
    "differential equation:\n",
    "\n",
    "$$\n",
    "J \\frac{d\\omega(t)}{dt} = K_T u(t) - T_L(t) - B \\omega(t),\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $J$ is the moment of inertia of the motor,\n",
    "- $B$ is the friction coefficient of the motor, and\n",
    "- $K_T$ is the torque constant of the motor.\n",
    "\n",
    "#### Exercise 1.1.1\n",
    "\n",
    "Implement the `MotorDynamics` interface that has a method `__call__(t)`, which returns the angular velocity of a motor at time `t`. \n",
    "The angular velocity should be such that it satisfies the differential equation above. An implementation of the `MotorDynamics` interface will\n",
    "need the following parameters:\n",
    "- `J`: the moment of inertia $J$,\n",
    "- `B`: the friction coefficient $B$,\n",
    "- `K_T`: the torque constant $K_T$,\n",
    "- `u`: a function that takes a time `t` and returns the current $u(t)$,\n",
    "- `T_L`: a function that takes a time `t` and returns the current $T_L(t)$, and\n",
    "- `omega_0`: the initial angular velocity of the motor.\n",
    "\n",
    "Once this is done, the `animate` method on the `Motor` class will animate the motor's state over time.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint (a big one!) </summary>\n",
    "\n",
    "> #### Solving with the Euler Method\n",
    ">\n",
    "> You can solve the differential equation above in many ways, but a simple numerical way to do it is by using the **Euler method**. The idea is the following:\n",
    "> 1. **Discretize** the continuous time differential equation into a **discrete time difference equation**. In this case, we can assume a zero-order hold on $\\omega(t)$.\n",
    ">     $$\n",
    ">     \\frac{d\\omega(t)}{dt} \\approx \\frac{\\omega[k+1] - \\omega[k]}{\\Delta t}, \\quad \\text{where } \\Delta t \\text{ is the time step.}\n",
    ">     $$\n",
    "> 2. **Substitute** it into the differential equation to get the difference equation:\n",
    ">     $$\n",
    ">     \\omega[k+1] = \\omega[k] + \\frac{\\Delta t}{J} (K_T u[k] - T_L[k] - B \\omega[k]), \\quad \\text{for } k = 0, 1, 2, \\ldots\n",
    ">     $$\n",
    "> 3. Implement the difference equation in the `__call__` method. It would make sense to **store the current angular velocity** as an attribute,\n",
    ">    so that you can use it to calculate the next angular velocity efficiently.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary> Hint (another one!) </summary>\n",
    "\n",
    "> #### Solving with Integrating Factors\n",
    ">\n",
    "> You can solve the above differential equation analytically by using the method of integrating factors. The result will be the following integral:\n",
    "> $$\n",
    "> \\omega(t) = e^{-at} \\left( \\omega_0 + \\frac{1}{J} \\int_0^t e^{a\\tau} g(\\tau) d\\tau \\right), \\quad \\text{where } a = \\frac{B}{J}, \\, g(\\tau) = K_T u(\\tau) - T_L(\\tau).\n",
    "> $$\n",
    ">\n",
    "> Although, for performance reasons, you can use the following version of the equation:\n",
    "> $$\n",
    "> \\omega(t) = e^{-at} \\left( \\omega_0 + \\frac{1}{J} \\left[\\int_0^{t'} e^{a\\tau} g(\\tau) d\\tau + \\int_{t'}^t e^{a\\tau} g(\\tau) d\\tau\\right] \\right), \\quad \\text{where } t' \\text{ is the last time step for which } \\omega(t') \\text{ is known}.\n",
    "> $$\n",
    ">\n",
    "> Reuse the result of the integral and this version will be faster, since the simulation will need to calculate the angular acceleration for successive values of $t$. \n",
    "> You can use `scipy.integrate.quad` to calculate the value of the integral.  \n",
    ">\n",
    "> This method should generally be more accurate than the Euler method, but it really depends on how you perform the numerical integration.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a4be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "\n",
    "class MotorDynamics(Protocol):\n",
    "    def __call__(self, t: float, /) -> float:\n",
    "        \"\"\"Return the angular acceleration at time t.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the motor dynamics.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class TemperatureModel(Protocol):\n",
    "    def __call__(self, t: float, /) -> float:\n",
    "        \"\"\"Return the temperature of the motor winding at time t.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the temperature model.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class ControlSignal(Protocol):\n",
    "    def __call__(self, t: float, /) -> float:\n",
    "        \"\"\"Return the control signal at time t.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class Load(Protocol):\n",
    "    def __call__(self, t: float, /) -> float:\n",
    "        \"\"\"Return the load at time t.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "# The following are implementations of the above protocols, although not the best ones. Nevertheless, they still come in handy.\n",
    "# Go further to see where you need to implement the protocols.\n",
    "\n",
    "\n",
    "class NoMotorDynamics:\n",
    "    def __call__(self, t: float) -> float:\n",
    "        return 0.0\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class NoTemperatureModel:\n",
    "    def __call__(self, t: float) -> float:\n",
    "        return 0.0\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class NoControlSignal:\n",
    "    def __call__(self, t: float) -> float:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class NoLoad:\n",
    "    def __call__(self, t: float) -> float:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final, Callable\n",
    "from dataclasses import dataclass, KW_ONLY, field\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# {% if not exercise['1.1.1'].solution %}\n",
    "# You can create an implementation of the `MotorDynamics` protocol like this:\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EulerMotorDynamics:  # {# type: ignore #}\n",
    "    _: KW_ONLY  # Keyword-only arguments are good, so you don't mix up your arguments\n",
    "    J: Final[float]\n",
    "    B: Final[float]\n",
    "    K_T: Final[float]\n",
    "    u: Final[ControlSignal]\n",
    "    T_L: Final[Load]\n",
    "    omega_0: Final[float] = 0.0\n",
    "\n",
    "    # You can add more attributes here if you need to store additional state.\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "\n",
    "    # More methods would go here if you need them.\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        # TODO: If you do use mutable state, you should reset it here.\n",
    "        pass\n",
    "\n",
    "\n",
    "# {% else %}\n",
    "# TODO: Review me!\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EulerMotorDynamics:\n",
    "    _: KW_ONLY  # Keyword-only arguments are good, so you don't mix up your arguments\n",
    "    J: Final[float]\n",
    "    B: Final[float]\n",
    "    K_T: Final[float]\n",
    "    u: Final[ControlSignal]\n",
    "    T_L: Final[Load]\n",
    "    omega_0: Final[float] = 0.0\n",
    "\n",
    "    t_last: float = field(init=False)\n",
    "    omega_last: float = field(init=False)\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        assert (\n",
    "            t >= self.t_last\n",
    "        ), \"The specified time point must be greater than or equal to the last one.\"\n",
    "\n",
    "        dt = t - self.t_last\n",
    "        omega = self.omega_last + dt * self.current_angular_acceleration()\n",
    "\n",
    "        # Don't forget to update the t and omega to be the most recent values\n",
    "        self.t_last = t\n",
    "        self.omega_last = omega\n",
    "\n",
    "        return omega\n",
    "\n",
    "    def current_angular_acceleration(self) -> float:\n",
    "        t_last, omega_last = self.t_last, self.omega_last\n",
    "\n",
    "        return (\n",
    "            self.u(t_last) * self.K_T - self.T_L(t_last) - self.B * omega_last\n",
    "        ) / self.J\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.t_last = 0\n",
    "        self.omega_last = self.omega_0\n",
    "\n",
    "\n",
    "# The following solves the same problem using the integrating factors approach.\n",
    "# The generic solver is implemented separately, since it also comes in handy later on.\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IntegratingFactorsSolver:\n",
    "    _: KW_ONLY\n",
    "    a: Final[float]\n",
    "    g: Final[Callable[[float], float]]\n",
    "    y_0: Final[float]\n",
    "\n",
    "    t_last: float = field(init=False)\n",
    "    y_last: float = field(init=False)\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        assert (\n",
    "            t >= self.t_last\n",
    "        ), \"The specified time point must be greater than or equal to the last one.\"\n",
    "\n",
    "        integral = (\n",
    "            self.integral_last\n",
    "            + quad(lambda tau: np.exp(self.a * tau) * self.g(tau), self.t_last, t)[0]\n",
    "        )\n",
    "        y = np.exp(-self.a * t) * (self.y_0 + integral)\n",
    "\n",
    "        # Don't forget to update the t and omega to be the most recent values\n",
    "        self.t_last = t\n",
    "        self.integral_last = integral\n",
    "\n",
    "        return y\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.t_last = 0\n",
    "        self.integral_last = 0\n",
    "\n",
    "\n",
    "class IntegratingMotorDynamics:\n",
    "    solver: Final[IntegratingFactorsSolver]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        J: float,\n",
    "        B: float,\n",
    "        K_T: float,\n",
    "        u: ControlSignal,\n",
    "        T_L: Load,\n",
    "        omega_0: float = 0.0,\n",
    "    ) -> None:\n",
    "        self.solver = IntegratingFactorsSolver(\n",
    "            a=B / J,\n",
    "            g=lambda t: (K_T * u(t) - T_L(t)) / J,\n",
    "            y_0=omega_0,\n",
    "        )\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        return self.solver(t)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.solver.reset()\n",
    "\n",
    "\n",
    "# {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a54f22",
   "metadata": {},
   "source": [
    "Once you implement your motor dynamics above, make sure to create it in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824150ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motor_dynamics(\n",
    "    *, J: float, B: float, K_T: float, u: ControlSignal, T_L: Load, omega_0: float = 0.0\n",
    ") -> MotorDynamics:\n",
    "    # {% if exercise['1.1.1'].solution %}\n",
    "    # TODO: Review me!\n",
    "    return IntegratingMotorDynamics(J=J, B=B, K_T=K_T, u=u, T_L=T_L, omega_0=omega_0)\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "faa2018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, TypeAlias, ClassVar\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objects import Figure, Frame, Scatter\n",
    "\n",
    "Vector: TypeAlias = NDArray[np.floating]\n",
    "\n",
    "\n",
    "def padded_range_for(\n",
    "    data: Vector | tuple[float, float], padding: float = 0.1\n",
    ") -> tuple[float, float]:\n",
    "    if len(data) == 0:\n",
    "        lower, upper = 0, 1\n",
    "    else:\n",
    "        lower, upper = min(data), max(data)\n",
    "        lower, upper = min(0, lower), max(1, upper)\n",
    "\n",
    "    delta = upper - lower\n",
    "\n",
    "    return lower - padding * delta, upper + padding * delta\n",
    "\n",
    "\n",
    "def draw_motor_housing() -> Scatter:\n",
    "    theta = np.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "    return Scatter(\n",
    "        x=np.cos(theta),\n",
    "        y=np.sin(theta),\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"blue\"),\n",
    "        name=\"Motor Housing\",\n",
    "        legendgroup=\"Motor\",\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TemperatureThresholds:\n",
    "    upper: float\n",
    "    lower: float\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class SimulationResults:\n",
    "    t_f: float\n",
    "    _: KW_ONLY\n",
    "    t: Vector\n",
    "    theta: Vector\n",
    "    omega: Vector\n",
    "    T: Vector\n",
    "    T_predicted: Vector\n",
    "    u: Vector\n",
    "    T_L: Vector\n",
    "\n",
    "    t_range: tuple[float, float]\n",
    "    omega_range: tuple[float, float]\n",
    "    T_range: tuple[float, float]\n",
    "    u_range: tuple[float, float]\n",
    "    T_L_range: tuple[float, float]\n",
    "\n",
    "    show_predicted: bool\n",
    "    thresholds: TemperatureThresholds | None\n",
    "\n",
    "    MOTOR_HOUSING_TRACE: ClassVar[Scatter] = draw_motor_housing()\n",
    "\n",
    "    @staticmethod\n",
    "    def create(\n",
    "        t_f: float,\n",
    "        *,\n",
    "        t: Vector,\n",
    "        theta: Vector,\n",
    "        omega: Vector,\n",
    "        T: Vector,\n",
    "        T_predicted: Vector,\n",
    "        u: Vector,\n",
    "        T_L: Vector,\n",
    "        thresholds: TemperatureThresholds | None,\n",
    "    ) -> \"SimulationResults\":\n",
    "        return SimulationResults(\n",
    "            t_f,\n",
    "            t=t,\n",
    "            theta=theta,\n",
    "            omega=omega,\n",
    "            T=T,\n",
    "            T_predicted=T_predicted,\n",
    "            u=u,\n",
    "            T_L=T_L,\n",
    "            t_range=padded_range_for((0, t_f)),\n",
    "            omega_range=padded_range_for(omega),\n",
    "            T_range=padded_range_for(T),\n",
    "            u_range=padded_range_for(u),\n",
    "            T_L_range=padded_range_for(T_L),\n",
    "            show_predicted=bool(np.any(T_predicted)),\n",
    "            thresholds=thresholds,\n",
    "        )\n",
    "\n",
    "    def until(self, step: int) -> \"SimulationResults\":\n",
    "        return SimulationResults(\n",
    "            self.t_f,\n",
    "            t=self.t[:step],\n",
    "            theta=self.theta[:step],\n",
    "            omega=self.omega[:step],\n",
    "            T=self.T[:step],\n",
    "            T_predicted=self.T_predicted[:step],\n",
    "            u=self.u[:step],\n",
    "            T_L=self.T_L[:step],\n",
    "            t_range=self.t_range,\n",
    "            omega_range=self.omega_range,\n",
    "            T_range=self.T_range,\n",
    "            u_range=self.u_range,\n",
    "            T_L_range=self.T_L_range,\n",
    "            show_predicted=self.show_predicted,\n",
    "            thresholds=self.thresholds,\n",
    "        )\n",
    "\n",
    "    def draw(self) -> Figure:\n",
    "        figure = self.create_layout()\n",
    "\n",
    "        self.draw_motor_on(figure)\n",
    "        self.draw_angular_velocity_on(figure)\n",
    "        self.draw_temperature_on(figure)\n",
    "        self.draw_control_signal_on(figure)\n",
    "        self.draw_load_on(figure)\n",
    "\n",
    "        return figure\n",
    "\n",
    "    def save_measurements_to(self, path: str, /, *, noise: float = 0.1) -> None:\n",
    "        # We save the temperature measurements to a CSV file and simulate gaussian noise\n",
    "        # with a standard deviation of `noise`. We also add some other random data to make it\n",
    "        # more confusing, just line in real life.\n",
    "\n",
    "        # Set seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Motor Housing Vibration Amplitude (mm)\": np.abs(\n",
    "                    np.random.normal(0, 0.5, len(self.t))\n",
    "                )\n",
    "                + np.abs(np.sin(self.t)),\n",
    "                \"Motor Winding Temperature (C)\": self.T\n",
    "                + np.random.normal(0, noise, len(self.T)),\n",
    "                \"Chroniton Displacement Current (A)\": np.random.normal(\n",
    "                    0, 0.1, len(self.t)\n",
    "                ),\n",
    "                \"Elapsed Time (s)\": self.t,\n",
    "            }\n",
    "        ).to_csv(path, index=False)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"\"\n",
    "\n",
    "    @property\n",
    "    def theta_f(self) -> float:\n",
    "        return self.theta[-1]\n",
    "\n",
    "    def create_layout(self) -> Figure:\n",
    "        return make_subplots(\n",
    "            rows=2,\n",
    "            cols=3,\n",
    "            column_widths=[0.4, 0.3, 0.3],\n",
    "            row_heights=[0.5, 0.5],\n",
    "            horizontal_spacing=0.1,\n",
    "            subplot_titles=(\n",
    "                \"Motor State\",\n",
    "                \"Angular Velocity\",\n",
    "                \"Temperature\",\n",
    "                \"Control Signal\",\n",
    "                \"Load\",\n",
    "            ),\n",
    "            specs=[\n",
    "                [{\"rowspan\": 2, \"type\": \"xy\"}, {\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
    "                [None, {\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
    "            ],\n",
    "        ).update_layout(height=750)\n",
    "\n",
    "    def draw_motor_on(self, figure: Figure) -> None:\n",
    "        figure.add_trace(self.MOTOR_HOUSING_TRACE, row=1, col=1)\n",
    "        figure.add_trace(\n",
    "            Scatter(\n",
    "                x=[0, np.cos(self.theta_f)],\n",
    "                y=[0, np.sin(self.theta_f)],\n",
    "                mode=\"lines+markers\",\n",
    "                marker=dict(size=10),\n",
    "                line=dict(width=2, color=\"red\"),\n",
    "                name=\"Motor Indicator\",\n",
    "                legendgroup=\"Motor\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        figure.update_xaxes(range=[-1.5, 1.5], row=1, col=1)\n",
    "\n",
    "        # Ensure the aspect ratio is square\n",
    "        figure.update_layout(\n",
    "            xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
    "            yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        )\n",
    "\n",
    "    def draw_angular_velocity_on(self, figure: Figure) -> None:\n",
    "        figure.add_trace(\n",
    "            Scatter(x=self.t, y=self.omega, mode=\"lines\", name=\"Angular Velocity\"),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "        figure.update_xaxes(title_text=\"Time (s)\", row=1, col=2, range=self.t_range)\n",
    "        figure.update_yaxes(\n",
    "            title_text=\"Angular Velocity (rad/s)\", row=1, col=2, range=self.omega_range\n",
    "        )\n",
    "\n",
    "    def draw_temperature_on(self, figure: Figure) -> None:\n",
    "        figure.add_trace(\n",
    "            Scatter(x=self.t, y=self.T, mode=\"lines\", name=\"Temperature\"),\n",
    "            row=1,\n",
    "            col=3,\n",
    "        )\n",
    "\n",
    "        if self.show_predicted:\n",
    "            figure.add_trace(\n",
    "                Scatter(\n",
    "                    x=self.t,\n",
    "                    y=self.T_predicted,\n",
    "                    mode=\"lines\",\n",
    "                    name=\"Predicted Temperature\",\n",
    "                    line=dict(dash=\"dash\"),\n",
    "                ),\n",
    "                row=1,\n",
    "                col=3,\n",
    "            )\n",
    "\n",
    "        if self.thresholds is not None:\n",
    "            figure.add_hline(\n",
    "                y=self.thresholds.upper,\n",
    "                line=dict(color=\"red\", width=1, dash=\"dash\"),\n",
    "                annotation_text=\"Overheating Threshold\",\n",
    "                annotation_position=\"top right\",\n",
    "                annotation_font=dict(size=8),\n",
    "                row=1,\n",
    "                col=3,\n",
    "            )\n",
    "\n",
    "            figure.add_hline(\n",
    "                y=self.thresholds.lower,\n",
    "                line=dict(color=\"green\", width=1, dash=\"dash\"),\n",
    "                annotation_text=\"Cooling Threshold\",\n",
    "                annotation_position=\"bottom right\",\n",
    "                annotation_font=dict(size=8),\n",
    "                row=1,\n",
    "                col=3,\n",
    "            )\n",
    "\n",
    "        figure.update_xaxes(title_text=\"Time (s)\", row=1, col=3, range=self.t_range)\n",
    "        figure.update_yaxes(\n",
    "            title_text=\"Temperature (°C)\", row=1, col=3, range=self.T_range\n",
    "        )\n",
    "\n",
    "    def draw_control_signal_on(self, figure: Figure) -> None:\n",
    "        figure.add_trace(\n",
    "            Scatter(x=self.t, y=self.u, mode=\"lines\", name=\"Control Signal\"),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "        figure.update_xaxes(title_text=\"Time (s)\", row=2, col=2, range=self.t_range)\n",
    "        figure.update_yaxes(\n",
    "            title_text=\"Control Signal (A)\", row=2, col=2, range=self.u_range\n",
    "        )\n",
    "\n",
    "    def draw_load_on(self, figure: Figure) -> None:\n",
    "        figure.add_trace(\n",
    "            Scatter(x=self.t, y=self.T_L, mode=\"lines\", name=\"Load\"), row=2, col=3\n",
    "        )\n",
    "\n",
    "        figure.update_xaxes(title_text=\"Time (s)\", row=2, col=3, range=self.t_range)\n",
    "        figure.update_yaxes(title_text=\"Load (N)\", row=2, col=3, range=self.T_L_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf9cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from dataclasses import replace\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Motor:\n",
    "    name: str\n",
    "    _: KW_ONLY\n",
    "    omega: MotorDynamics = NoMotorDynamics()\n",
    "    T: TemperatureModel = NoTemperatureModel()\n",
    "    u: ControlSignal = NoControlSignal()\n",
    "    T_L: Load = NoLoad()\n",
    "\n",
    "    T_predicted: TemperatureModel = NoTemperatureModel()\n",
    "\n",
    "    def with_dynamics(self, omega: MotorDynamics) -> \"Motor\":\n",
    "        return replace(self, omega=omega)\n",
    "\n",
    "    def with_temperature(self, T: TemperatureModel) -> \"Motor\":\n",
    "        return replace(self, T=T)\n",
    "\n",
    "    def with_control_signal(self, u: ControlSignal) -> \"Motor\":\n",
    "        return replace(self, u=u)\n",
    "\n",
    "    def with_load(self, T_L: Load) -> \"Motor\":\n",
    "        return replace(self, T_L=T_L)\n",
    "\n",
    "    def with_predicted_temperature(self, T_predicted: TemperatureModel) -> \"Motor\":\n",
    "        return replace(self, T_predicted=T_predicted)\n",
    "\n",
    "    def animate(\n",
    "        self,\n",
    "        *,\n",
    "        t_f: float,\n",
    "        steps: int = 100,\n",
    "        thresholds: TemperatureThresholds | None = None,\n",
    "    ) -> SimulationResults:\n",
    "        results = self.simulate(t_f=t_f, steps=steps, thresholds=thresholds)\n",
    "        frames = self.create_frames(results, steps)\n",
    "        starting_frame = frames[0]\n",
    "\n",
    "        Figure(\n",
    "            data=starting_frame.data,\n",
    "            layout=starting_frame.layout,\n",
    "            frames=[Frame(data=frame.data) for frame in frames],\n",
    "        ).update_layout(\n",
    "            title=f\"Animated {self.name}\",\n",
    "            updatemenus=[self._animation_configuration()],\n",
    "        ).show()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def simulate(\n",
    "        self, *, t_f: float, steps: int, thresholds: TemperatureThresholds | None = None\n",
    "    ) -> SimulationResults:\n",
    "        self.omega.reset()\n",
    "        self.T.reset()\n",
    "        self.T_predicted.reset()\n",
    "\n",
    "        t = np.linspace(0, t_f, steps)\n",
    "        theta = np.zeros(steps)\n",
    "        omega = np.zeros(steps)\n",
    "        T = np.zeros(steps)\n",
    "        u = np.zeros(steps)\n",
    "        T_L = np.zeros(steps)\n",
    "        T_predicted = np.zeros(steps)\n",
    "\n",
    "        # We do the first step manually\n",
    "        omega[0] = self.omega(0)\n",
    "        T[0] = self.T(0)\n",
    "        u[0] = self.u(0)\n",
    "        T_L[0] = self.T_L(0)\n",
    "        T_predicted[0] = self.T_predicted(0)\n",
    "\n",
    "        for i, t_i in tqdm(\n",
    "            enumerate(t[1:], start=1),\n",
    "            desc=f\"Simulating {self.name}\",\n",
    "            total=steps,\n",
    "            initial=1,\n",
    "            unit=\" time step\",\n",
    "        ):\n",
    "            dt = t_i - t[i - 1]\n",
    "            theta[i] = theta[i - 1] + omega[i - 1] * dt\n",
    "            omega[i] = self.omega(t_i)\n",
    "            T[i] = self.T(t_i)\n",
    "            u[i] = self.u(t_i)\n",
    "            T_L[i] = self.T_L(t_i)\n",
    "            T_predicted[i] = self.T_predicted(t_i)\n",
    "\n",
    "        return SimulationResults.create(\n",
    "            t_f,\n",
    "            t=t,\n",
    "            omega=omega,\n",
    "            T=T,\n",
    "            T_predicted=T_predicted,\n",
    "            u=u,\n",
    "            T_L=T_L,\n",
    "            theta=theta,\n",
    "            thresholds=thresholds,\n",
    "        )\n",
    "\n",
    "    def create_frames(self, results: SimulationResults, steps: int) -> list[Figure]:\n",
    "        return [results.until(i).draw() for i in range(1, steps + 1)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _animation_configuration() -> dict[str, Any]:\n",
    "        return dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 10, \"redraw\": False},\n",
    "                            \"fromcurrent\": True,\n",
    "                            \"transition\": {\"duration\": 0},\n",
    "                        },\n",
    "                    ],\n",
    "                )\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d0da5",
   "metadata": {},
   "source": [
    "Let's check out what the motor looks like when it's running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No control signal, no load\n",
    "u: ControlSignal = lambda _: 0.0\n",
    "T_L: Load = lambda _: 0.0\n",
    "\n",
    "morton = (\n",
    "    Motor(name=\"Morton\")\n",
    "    .with_control_signal(u)\n",
    "    .with_load(T_L)\n",
    "    .with_dynamics(motor_dynamics(J=1.0, B=0.1, K_T=1.0, u=u, T_L=T_L))\n",
    ")\n",
    "\n",
    "morton.animate(t_f=10.0, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant control signal, but no load\n",
    "u: ControlSignal = lambda _: 1.0\n",
    "T_L: Load = lambda _: 0.0\n",
    "\n",
    "motorola = (\n",
    "    Motor(\"Motorola\")\n",
    "    .with_control_signal(u)\n",
    "    .with_load(T_L)\n",
    "    .with_dynamics(motor_dynamics(J=1.0, B=0.1, K_T=1.0, u=u, T_L=T_L))\n",
    ")\n",
    "\n",
    "motorola.animate(t_f=10.0, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69140d98",
   "metadata": {},
   "source": [
    "### 1.2. Motor Temperature\n",
    "\n",
    "Now that our motor is up and running, you may have noticed that the temperature is always stuck at zero. This is because we aren't really monitoring\n",
    "the temperature of the motor winding during the simulation in any way. Let's fix that by adding a temperature \"sensor\" to the motor.\n",
    "\n",
    "When we create the controller later on, it won't know the actual temperature of the winding though. Gaussian Process Regression will have to predict it, \n",
    "but we will be able to verify the predictions by comparing them to the actual temperature values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5aa7c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Temperature (you can skip this)</summary>\n",
    "\n",
    "The following describes how we simulate a \"temperature sensor\" for the motor winding. You can skip this if you're not interested in the details.\n",
    "\n",
    "To model the temperature dynamics of the motor winding, we will use the following differential equation:\n",
    "  \n",
    "$$\n",
    "C_t \\frac{dT(t)}{dt} = u^2(t)R - k(T(t) - T_{amb})\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $C_t$ is the thermal capacity of the motor winding,\n",
    "- $R$ is the resistance of the motor winding,\n",
    "- $k$ is the heat transfer coefficient of the motor, and\n",
    "- $T_{amb}$ is the ambient temperature.\n",
    "\n",
    "To keep the computation times reasonably low, we will solve this differential equation using integrating factors:\n",
    "\n",
    "$$\n",
    "T(t) = e^{-at} \\left( T_0 + \\frac{1}{C_t} \\left[\\int_0^{t'} e^{a\\tau} g(\\tau) d\\tau + \\int_{t'}^t e^{a\\tau} g(\\tau) d\\tau\\right] \\right), \\\\\n",
    "\\text{where } a = \\frac{k}{C_t}, \\, g(\\tau) = u^2(\\tau)R + kT_{amb}, \\text{ and } t' \\text{ is the last time step for which } T(t') \\text{ is known}.\n",
    "$$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9877b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemperatureSensor:\n",
    "    solver: Final[IntegratingFactorsSolver]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        C_t: float,\n",
    "        R: float,\n",
    "        k: float,\n",
    "        T_ambient: float,\n",
    "        u: ControlSignal,\n",
    "        T_0: float,\n",
    "    ) -> None:\n",
    "        self.solver = IntegratingFactorsSolver(\n",
    "            a=k / C_t,\n",
    "            g=lambda t: (u(t) ** 2 * R + k * T_ambient) / C_t,\n",
    "            y_0=T_0,\n",
    "        )\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        return self.solver(t)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.solver.reset()\n",
    "\n",
    "    @staticmethod\n",
    "    def for_motor(\n",
    "        motor: Motor,\n",
    "        *,\n",
    "        C_t: float = 40,  # J/°C\n",
    "        R: float = 2,  # Ω\n",
    "        k: float = 0.5,  # W/°C\n",
    "        T_ambient: float = 25,  # °C\n",
    "        T_0: float = 25,  # °C\n",
    "    ) -> \"TemperatureSensor\":\n",
    "        return TemperatureSensor(\n",
    "            C_t=C_t, R=R, k=k, T_ambient=T_ambient, u=motor.u, T_0=T_0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant control signal and load, that turns off after 150 seconds\n",
    "u: ControlSignal = lambda t: 1.0 if t < 150.0 else 0.0\n",
    "T_L: Load = lambda t: 0.5 if t < 150.0 else 0.0\n",
    "\n",
    "morton = (\n",
    "    Motor(\"Morton\")\n",
    "    .with_control_signal(u)\n",
    "    .with_load(T_L)\n",
    "    .with_dynamics(motor_dynamics(J=1.0, B=0.1, K_T=1.0, u=u, T_L=T_L))\n",
    ")\n",
    "\n",
    "# Let's also see what the temperature looks like.\n",
    "morton = morton.with_temperature(TemperatureSensor.for_motor(morton))\n",
    "\n",
    "# The simulation is also longer\n",
    "morton.animate(t_f=300.0, steps=200).save_measurements_to(\"motor_temperature_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b150504",
   "metadata": {},
   "source": [
    "### 1.3. Motor Temperature Data\n",
    "\n",
    "Time for the fun part! A colleague of yours has collected some temperature measurements for motors. They ran the motor at full power, then turned it off,\n",
    "and recorded the changes in temperature over time for the whole process. This data is stored in the file `motor_temperature_data.csv`.\n",
    "\n",
    "#### Exercise 1.3.1\n",
    "\n",
    "Load the data from the file `motor_temperature_data.csv` and understand its structure. \n",
    "\n",
    "- What type of data is it? \n",
    "- How many *important* columns are there? \n",
    "- What do they represent?\n",
    "\n",
    "Once you've done that, the next logical thing to do would be to visualize the data. You'll find a cool plotting function below to help you with that.\n",
    "\n",
    "You can use a convenient library called `pandas` to load the data. Let your web searching power guide you through the rest of the process.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> Pandas has a `read_csv` function exactly for such situations. You can also use it in conjunction with the `head` method to get a quick look at the data.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a52e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temperature(*, t: Vector, T: Vector) -> Figure:\n",
    "    return Figure(\n",
    "        data=[\n",
    "            Scatter(\n",
    "                x=t,\n",
    "                y=T,\n",
    "                mode=\"markers\",\n",
    "                name=\"Temperature\",\n",
    "                marker=dict(size=5, symbol=\"cross\"),\n",
    "            )\n",
    "        ],\n",
    "        layout=dict(\n",
    "            title=\"Motor Winding Temperature\",\n",
    "            xaxis=dict(title=\"Time (s)\"),\n",
    "            yaxis=dict(title=\"Temperature (°C)\"),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {% if not exercise['1.3.1'].solution %}\n",
    "# TODO: Implement me!\n",
    "print(\"Oops! Looks like you forgot to implement this cell.\")\n",
    "# {% else %}\n",
    "# TODO: Review me!\n",
    "\n",
    "# Let's read in the file first.\n",
    "temperature_data = pd.read_csv(\"motor_temperature_data.csv\")\n",
    "\n",
    "# Now let's check out the first few rows.\n",
    "temperature_data.head()\n",
    "# {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf8f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from(temperature_data: pd.DataFrame) -> tuple[Vector, Vector]:\n",
    "    # {% if exercise['1.3.1'].solution %}\n",
    "    # TODO: Review me!\n",
    "    # Extract the temperature data.\n",
    "    t = np.array(temperature_data[\"Elapsed Time (s)\"])\n",
    "    T = np.array(temperature_data[\"Motor Winding Temperature (C)\"])\n",
    "\n",
    "    return t, T\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f464bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {% if exercise['1.3.1'].solution %}\n",
    "# TODO: Review me!\n",
    "# Extract the temperature data.\n",
    "t, T = extract_data_from(temperature_data)\n",
    "\n",
    "# Let's plot the temperature data.\n",
    "plot_temperature(t=t, T=T).show()\n",
    "# {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1c9a3",
   "metadata": {},
   "source": [
    "### 1.4. Reflection\n",
    "\n",
    "After looking at the data, consider the following questions:\n",
    "- What parts of the data could be useful for predicting the motor winding temperature?\n",
    "- Are there any distinct sections in the data that could provide more information?\n",
    "- Does the data look noisy? If so, how could you deal with the noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8166f40",
   "metadata": {},
   "source": [
    "Well, looks like that's the data you have to work with. While you think about what you can do with all those scattered points on your screen, \n",
    "let's get a quick refresher on how Gaussian Process Regression works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058664e",
   "metadata": {},
   "source": [
    "## 2. Gaussian Process Regression\n",
    "\n",
    "### 2.1. The Basics\n",
    "\n",
    "Unlike your regular linear regression, Gaussian Process Regression (GPR) does not directly assume a particular form for the underlying function relating\n",
    "the inputs to the outputs. Consequently, it doesn't estimate any parameters of the underlying function, since we don't know of any parameters to begin \n",
    "with. It does however, assume that adjacent points in the input space have some kind of relationship. This relationship is captured by a covariance \n",
    "function, also known as the kernel function, which is the core of GPR (pun intended).\n",
    "\n",
    "### 2.2. The Kernel Function\n",
    "\n",
    "The kernel of a GPR model represents the prior belief about the function we are trying to estimate. It measures the similarity between two points,\n",
    "($x_1$ and $x_2$), and determines how much a known data point at $x_1$ can influence the prediction at $x_2$ (or vice versa). \n",
    "\n",
    "The choice of this function largely determines the \"shape\" of the predictions and there are many options to choose from, but the kernel typically \n",
    "has the following properties:\n",
    "\n",
    "- If the points are close to each other, the kernel returns a large value, indicating that their values are highly correlated.\n",
    "- If the points are far apart, the kernel returns a small value, meaning their values are weakly correlated or uncorrelated.\n",
    "\n",
    "Throughout this exercise, we will represent it via the `Kernel` interface defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b79997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel(Protocol):\n",
    "    def __call__(self, x_1: float, x_2: float) -> float:\n",
    "        \"\"\"Computes the value of the kernel function for the two input points x_1 and x_2.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c6511",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercise 2.2.1\n",
    "\n",
    "Let's start with a common kernel function called the **Radial Basis Function (RBF)**. It is defined as:\n",
    "$$ k(x_1,x_2):= \\sigma^2*\\exp(-\\dfrac{(x_1-x_2)^2}{2l^2})$$\n",
    "\n",
    "where:\n",
    "- $\\sigma^2$ is the signal variance, which controls the vertical variation or amplitude of the function, and\n",
    "- $l > 0$ (sometimes written as $\\lambda$) is the length-scale, which controls how quickly the correlation between two points decreases as their distance increases.\n",
    "\n",
    "Implement the `__call__` method of the `RBF` class, which takes two inputs $x_1$ and $x_2$ and returns the value of the RBF kernel function at \n",
    "those points. Note that *sigma* and *l* are provided as instance attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc55090",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class RBFKernel:\n",
    "    _: KW_ONLY\n",
    "    sigma: float = 1.0\n",
    "    l: float = 1.0\n",
    "\n",
    "    def __call__(self, x_1: float, x_2: float) -> float:\n",
    "        # {% if exercise['2.2.1'].solution %}\n",
    "        # TODO: Review me!\n",
    "        return self.sigma**2 * np.exp(-((x_1 - x_2) ** 2) / (2 * self.l**2))\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        # This just prints the kernel in a nice way.\n",
    "        return f\"RBF(\\u03c3={self.sigma:.3f}, l={self.l:.3f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f614bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "Matrix: TypeAlias = NDArray[np.floating]\n",
    "\n",
    "\n",
    "class OnButtonClick(Protocol):\n",
    "    def __call__(self, figure: Figure) -> None:\n",
    "        \"\"\"Updates the figure when the button is clicked.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class OnParameterUpdate(Protocol):\n",
    "    def __call__(self, figure: Figure, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Returns the new y values for the figure.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Button:\n",
    "    name: str\n",
    "    _: KW_ONLY\n",
    "    on_click: OnButtonClick\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Slider:\n",
    "    name: str\n",
    "    _: KW_ONLY\n",
    "    min: float\n",
    "    max: float\n",
    "    step: float\n",
    "    default: float\n",
    "    description: str = \"\"\n",
    "\n",
    "\n",
    "def enable_plotly_latex() -> None:\n",
    "    plotly.offline.init_notebook_mode()\n",
    "    display(\n",
    "        HTML(\n",
    "            '<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def set_layout_for(\n",
    "    figure: Figure, *, title: str = \"\", x_title: str = \"Input\", y_title: str = \"Output\"\n",
    ") -> Figure:\n",
    "    figure.update_layout(\n",
    "        height=600,\n",
    "        title=title,\n",
    "        xaxis_title=x_title,\n",
    "        yaxis_title=y_title,\n",
    "        legend=dict(yanchor=\"top\", y=0.9, xanchor=\"right\", x=0.95),\n",
    "    )\n",
    "\n",
    "    return figure\n",
    "\n",
    "\n",
    "def line_scatter(\n",
    "    x: Vector,\n",
    "    y: Vector,\n",
    "    *,\n",
    "    name: str = \"Prediction\",\n",
    "    color: str = \"blue\",\n",
    "    dash: str = \"solid\",\n",
    "    visible: bool = True,\n",
    "    showlegend: bool = True,\n",
    ") -> Scatter:\n",
    "    return Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=name,\n",
    "        visible=visible,\n",
    "        showlegend=showlegend,\n",
    "        line=dict(color=color, width=2, dash=dash),\n",
    "    )\n",
    "\n",
    "\n",
    "def dot_scatter(\n",
    "    x: Vector,\n",
    "    y: Vector,\n",
    "    *,\n",
    "    name: str = \"Observed points\",\n",
    "    color: str = \"red\",\n",
    "    visible: bool = True,\n",
    "    showlegend: bool = True,\n",
    ") -> Scatter:\n",
    "    return Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=name,\n",
    "        visible=visible,\n",
    "        showlegend=showlegend,\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=color, size=8),\n",
    "    )\n",
    "\n",
    "\n",
    "def uncertainty_area_scatter(\n",
    "    x: Vector,\n",
    "    y_upper: Vector,\n",
    "    y_lower: Vector,\n",
    "    *,\n",
    "    name: str = \"Mean +/- Standard Deviation\",\n",
    "    visible: bool = True,\n",
    ") -> Scatter:\n",
    "    # We plot the upper bound first, which corresponds to the x values\n",
    "    # Then we plot the lower bound, but in reverse order, so that the area\n",
    "    # between the two lines is filled.\n",
    "    return Scatter(\n",
    "        x=np.concatenate((x, x[::-1])),\n",
    "        y=np.concatenate((y_upper, y_lower[::-1])),\n",
    "        name=name,\n",
    "        visible=visible,\n",
    "        showlegend=True,\n",
    "        fill=\"toself\",\n",
    "        fillcolor=\"rgba(189,195,199,0.5)\",\n",
    "        line=dict(color=\"rgba(200,200,200,0)\"),\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    "\n",
    "\n",
    "def label(\n",
    "    x: float,\n",
    "    y: float,\n",
    "    text: str,\n",
    "    *,\n",
    "    position: str = \"top right\",\n",
    "    font_size: int = 16,\n",
    "    color: str = \"black\",\n",
    ") -> Scatter:\n",
    "    return Scatter(\n",
    "        x=[x],\n",
    "        y=[y],\n",
    "        mode=\"text+markers\",\n",
    "        text=[text],\n",
    "        textposition=position,\n",
    "        textfont=dict(size=font_size, color=color),\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def interactive_figure(\n",
    "    data: list[Scatter],\n",
    "    *,\n",
    "    title: str,\n",
    "    x_title: str,\n",
    "    y_title: str,\n",
    "    buttons: list[Button] = [],\n",
    "    sliders: list[Slider] = [],\n",
    "    on_update: OnParameterUpdate | None = None,\n",
    ") -> Figure:\n",
    "    figure = set_layout_for(\n",
    "        go.FigureWidget(data=data), title=title, x_title=x_title, y_title=y_title\n",
    "    )\n",
    "\n",
    "    @interact(\n",
    "        **{\n",
    "            param.name: widgets.FloatSlider(\n",
    "                value=param.default,\n",
    "                min=param.min,\n",
    "                max=param.max,\n",
    "                step=param.step,\n",
    "                description=param.description or param.name,\n",
    "                style={\"description_width\": \"200px\"},\n",
    "                layout=widgets.Layout(width=\"35%\"),\n",
    "            )\n",
    "            for param in sliders\n",
    "        }\n",
    "    )\n",
    "    def update(**kwargs: Any) -> None:\n",
    "        assert (\n",
    "            not sliders or on_update is not None\n",
    "        ), \"You forgot to specify an update function (on_update).\"\n",
    "\n",
    "        if on_update is not None:\n",
    "            with figure.batch_update():\n",
    "                on_update(figure, **kwargs)\n",
    "\n",
    "    def click_handler_for(button: Button) -> Callable:\n",
    "        def click_handler(_) -> None:\n",
    "            with figure.batch_update():\n",
    "                button.on_click(figure)\n",
    "\n",
    "        return click_handler\n",
    "\n",
    "    button_components: list[widgets.Button] = []\n",
    "\n",
    "    for button in buttons:\n",
    "        component = widgets.Button(description=button.name)\n",
    "        component.on_click(click_handler_for(button))\n",
    "\n",
    "        button_components.append(component)\n",
    "\n",
    "    return widgets.VBox([figure, *button_components])\n",
    "\n",
    "\n",
    "enable_plotly_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23258da",
   "metadata": {},
   "source": [
    "Let's see what this kernel looks like. Run the cell below for an interactive visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class CovarianceCalculator:\n",
    "    x_values: Vector\n",
    "\n",
    "    def __call__(self, figure: Figure, *, l: float, sigma: float, x_2: float) -> None:\n",
    "        figure.data[0].y = self.calculate(l, sigma, x_2)\n",
    "\n",
    "        # Update the label for x_2\n",
    "        line = label(x=x_2, y=self.variance(l, sigma, x_2), text=\"$x_2$\")\n",
    "        figure.data[1].x = line.x\n",
    "        figure.data[1].y = line.y\n",
    "\n",
    "    def calculate(self, l: float, sigma: float, x_2: float) -> Vector:\n",
    "        kernel = RBFKernel(l=l, sigma=sigma)\n",
    "        return np.array([kernel(x, x_2) for x in self.x_values])\n",
    "\n",
    "    def variance(self, l: float, sigma: float, x_2: float) -> float:\n",
    "        kernel = RBFKernel(l=l, sigma=sigma)\n",
    "        return kernel(x_2, x_2)\n",
    "\n",
    "\n",
    "x_values = np.arange(-10, 10, 0.1)\n",
    "calculate_covariance = CovarianceCalculator(x_values)\n",
    "\n",
    "interactive_figure(\n",
    "    data=[\n",
    "        line_scatter(\n",
    "            x=x_values,\n",
    "            y=np.zeros_like(x_values),\n",
    "            name=\"Covariance\",\n",
    "        ),\n",
    "        label(x=0, y=0, text=\"$x_2$\"),\n",
    "    ],\n",
    "    title=\"Radial Basis Function Kernel\",\n",
    "    x_title=\"$x_1$\",\n",
    "    y_title=\"$RBF(x_1, x_2)$\",\n",
    "    sliders=[\n",
    "        Slider(\n",
    "            \"l\",\n",
    "            min=0.1,\n",
    "            max=3,\n",
    "            step=0.1,\n",
    "            default=1.0,\n",
    "            description=r\"Length scale (l)\",\n",
    "        ),\n",
    "        Slider(\n",
    "            \"sigma\",\n",
    "            min=0.1,\n",
    "            max=2,\n",
    "            step=0.01,\n",
    "            default=1.0,\n",
    "            description=r\"Signal variance (sigma)\",\n",
    "        ),\n",
    "        Slider(\n",
    "            \"x_2\",\n",
    "            min=-10,\n",
    "            max=10,\n",
    "            step=0.1,\n",
    "            default=0.0,\n",
    "            description=r\"Second input (x_2)\",\n",
    "        ),\n",
    "    ],\n",
    "    on_update=calculate_covariance,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f81bfc",
   "metadata": {},
   "source": [
    "### 2.3. The Covariance Matrix\n",
    "\n",
    "Hopefully your kernels looks nice and smooth, but it's not enough for a GPR model. The next ingredient is data. You would need to have some labeled\n",
    "data points (*training data*) with which you can update your prior belief about the function distribution, and the first step is to calculate the \n",
    "**covariance matrix**.\n",
    "\n",
    "Let's say you are given $n$ training points $x_1, x_2, \\ldots, x_m \\in \\mathbb{R}^n$ with values $y_1, y_2, \\ldots, y_m \\in \\mathbb{R}$. The covariance\n",
    "matrix $K'$ is a square matrix of size $m \\times m$ where the $(i, j)$-th element is given by the kernel function evaluated at $x_i$ and $x_j$:\n",
    "\n",
    "$$\n",
    "K' = \\begin{bmatrix}\n",
    "k(x_1, x_1) & k(x_1, x_2) & \\ldots & k(x_1, x_m) \\\\\n",
    "k(x_2, x_1) & k(x_2, x_2) & \\ldots & k(x_2, x_m) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "k(x_m, x_1) & k(x_m, x_2) & \\ldots & k(x_m, x_m)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "You can also define a more general covariance matrix $K(\\mathbf{x^{(1)}}, \\mathbf{x^{(2)}})$ between two vectors of points $\\mathbf{x^{(1)}}$ and $\\mathbf{x^{(2)}}$:\n",
    "\n",
    "$$\n",
    "K(\\mathbf{x^{(1)}}, \\mathbf{x^{(2)}}) = \\begin{bmatrix}\n",
    "k(x_1^{(1)}, x_1^{(2)}) & k(x_1^{(1)}, x_2^{(2)}) & \\ldots & k(x_1^{(1)}, x_m^{(2)}) \\\\\n",
    "k(x_2^{(1)}, x_1^{(2)}) & k(x_2^{(1)}, x_2^{(2)}) & \\ldots & k(x_2^{(1)}, x_m^{(2)}) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "k(x_m^{(1)}, x_1^{(2)}) & k(x_m^{(1)}, x_2^{(2)}) & \\ldots & k(x_m^{(1)}, x_m^{(2)})\n",
    "\\end{bmatrix}, \\quad \\text{so that } K' = K(\\mathbf{x}, \\mathbf{x}).\n",
    "$$\n",
    "\n",
    "These matrices can be used to update our function distribution based on the training data. Later on, we will also use them to make predictions at new points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20f94e",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercise 2.3.1\n",
    "\n",
    "Implement the `covariance_matrix` function given below. It takes two vectors of training points `x_1` and `x_2`, and the kernel function. It should\n",
    "return the covariance matrix $K(\\mathbf{x^{(1)}}, \\mathbf{x^{(2)}})$ as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "073e1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy import latex\n",
    "from IPython.display import Math\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FormattingContext:\n",
    "    _: KW_ONLY\n",
    "    m: int\n",
    "    n: int\n",
    "    start_limit: int\n",
    "    end_limit: int\n",
    "    precision: int\n",
    "    hide_small_values: bool\n",
    "    v_dots: sp.Symbol\n",
    "    c_dots: sp.Symbol\n",
    "    d_dots: sp.Symbol\n",
    "\n",
    "    @property\n",
    "    def limit(self) -> int:\n",
    "        return self.start_limit + self.end_limit\n",
    "\n",
    "    @staticmethod\n",
    "    def create_for(\n",
    "        matrix: Matrix,\n",
    "        *,\n",
    "        start_limit: int,\n",
    "        end_limit: int,\n",
    "        precision: int,\n",
    "        hide_small_values: bool,\n",
    "    ) -> \"FormattingContext\":\n",
    "        return FormattingContext(\n",
    "            m=matrix.shape[0],\n",
    "            n=matrix.shape[1],\n",
    "            start_limit=start_limit,\n",
    "            end_limit=end_limit,\n",
    "            precision=precision,\n",
    "            hide_small_values=hide_small_values,\n",
    "            v_dots=sp.symbols(r\"\\vdots\"),\n",
    "            c_dots=sp.symbols(r\"\\cdots\"),\n",
    "            d_dots=sp.symbols(r\"\\ddots\"),\n",
    "        )\n",
    "\n",
    "\n",
    "def truncate(matrix: Matrix, *, context: FormattingContext) -> sp.Matrix:\n",
    "    m, n = matrix.shape\n",
    "    start_limit = context.start_limit\n",
    "    end_limit = context.end_limit\n",
    "\n",
    "    if m <= context.limit and n <= context.limit:\n",
    "        return sp.Matrix(matrix)\n",
    "\n",
    "    rows = list(matrix[:start_limit])\n",
    "    if m > context.limit:\n",
    "        rows.extend(matrix[-end_limit:])\n",
    "\n",
    "    result = sp.Matrix(rows)\n",
    "\n",
    "    if n > context.limit:\n",
    "        result = result.extract(\n",
    "            [i for i in range(result.rows)],\n",
    "            list(range(start_limit)) + list(range(n - end_limit, n)),\n",
    "        )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def extend_horizontally(matrix: sp.Matrix, *, context: FormattingContext) -> sp.Matrix:\n",
    "    m = context.m\n",
    "    start_limit, limit = context.start_limit, context.limit\n",
    "    v_dots = context.v_dots\n",
    "\n",
    "    if m > limit:\n",
    "        columns = matrix.shape[1]\n",
    "        matrix = matrix.row_insert(\n",
    "            start_limit, sp.Matrix([[v_dots for _ in range(columns)]])\n",
    "        )\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def extend_vertically(matrix: sp.Matrix, *, context: FormattingContext) -> sp.Matrix:\n",
    "    n = context.n\n",
    "    start_limit, limit = context.start_limit, context.limit\n",
    "    c_dots = context.c_dots\n",
    "\n",
    "    if n > limit:\n",
    "        rows = matrix.shape[0]\n",
    "        matrix = matrix.col_insert(\n",
    "            start_limit, sp.Matrix([c_dots for _ in range(rows)])\n",
    "        )\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def extend_diagonally(matrix: sp.Matrix, *, context: FormattingContext) -> sp.Matrix:\n",
    "    m, n = context.m, context.n\n",
    "    start_limit, limit = context.start_limit, context.limit\n",
    "    d_dots = context.d_dots\n",
    "\n",
    "    if m > limit and n > limit:\n",
    "        matrix[start_limit, start_limit] = d_dots\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def format_numbers(matrix: sp.Matrix, *, context: FormattingContext) -> sp.Matrix:\n",
    "    precision = context.precision\n",
    "\n",
    "    def format_entry(entry: sp.Expr) -> sp.Symbol | float | str:\n",
    "        if isinstance(entry, sp.Symbol):\n",
    "            return entry\n",
    "\n",
    "        number = float(entry)\n",
    "        if abs(number) < 1e-3 and number != 0:\n",
    "            return 0 if context.hide_small_values else f\"{number:.{precision}e}\"\n",
    "        else:\n",
    "            return f\"{number:.{precision}f}\"\n",
    "\n",
    "    return sp.Matrix(\n",
    "        [[format_entry(value) for value in row] for row in matrix.tolist()]\n",
    "    )\n",
    "\n",
    "\n",
    "def pretty(\n",
    "    matrix: Matrix,\n",
    "    *,\n",
    "    start_limit: int = 5,\n",
    "    end_limit: int = 5,\n",
    "    precision: int = 3,\n",
    "    hide_small_values: bool = True,\n",
    ") -> None:\n",
    "    context = FormattingContext.create_for(\n",
    "        matrix,\n",
    "        start_limit=start_limit,\n",
    "        end_limit=end_limit,\n",
    "        precision=precision,\n",
    "        hide_small_values=hide_small_values,\n",
    "    )\n",
    "\n",
    "    symbolic = truncate(matrix, context=context)\n",
    "    symbolic = extend_horizontally(symbolic, context=context)\n",
    "    symbolic = extend_vertically(symbolic, context=context)\n",
    "    symbolic = extend_diagonally(symbolic, context=context)\n",
    "    symbolic = format_numbers(symbolic, context=context)\n",
    "\n",
    "    display(Math(latex(symbolic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c695e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_matrix(x_1: Vector, x_2: Vector, kernel: Kernel) -> Matrix:\n",
    "    # {% if exercise['2.3.1'].solution %}\n",
    "    # TODO: Review me!\n",
    "    return np.array([[kernel(a, b) for a in x_1] for b in x_2])\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb6b86",
   "metadata": {},
   "source": [
    "Try calculating the covariance matrix for some random points using the RBF kernel you implemented earlier. You can use the `pretty` \n",
    "function to print the matrix in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 100)  # This can be both your x_1 and x_2\n",
    "\n",
    "# {% if not exercise['2.3.1'].solution %}\n",
    "# TODO: Implement me!\n",
    "print(\"Oops! Looks like you forgot to implement this cell.\")\n",
    "# {% else %}\n",
    "# TODO: Review me!\n",
    "kernel = RBFKernel(sigma=1.0, l=1.0)\n",
    "K = covariance_matrix(x, x, kernel)\n",
    "pretty(K)\n",
    "# {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306c3b7",
   "metadata": {},
   "source": [
    "## 2.4. Predictions\n",
    "\n",
    "To actually incorporate the training data into the model, we need to update some parameters of our expected function distribution. The result of this\n",
    "update is the **posterior distribution**. We are assuming a multivariate Gaussian distribution for the function values, so the corresponding parameters\n",
    "are the mean $\\mu$ and the covariance $\\Sigma$ of the distribution.\n",
    "\n",
    "The posterior distribution is given by:\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mu=K_*K^{-1}y, \\Sigma=K_{**} - K_*K^{-1}K_*^T)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $K$ is the covariance matrix between all pairs of training points,\n",
    "- $K_*$ is the covariance matrix between the training points and the test points,\n",
    "- $K_{**}$ is the covariance matrix between the test points themselves, and\n",
    "- $y$ is the vector of training values.\n",
    "\n",
    "To account for the noise that is most likely present in our data, we also add a small value $\\sigma_e^2$ to the diagonal of $K'$. \n",
    "This value is called the **noise variance** and it represents the uncertainty in the data. This final covariance matrix $K$ is then:\n",
    "\n",
    "$$\n",
    "K = K' + \\sigma_e^2 \\mathbb{I}_m, \\quad \\text{where } \\mathbb{I}_m \\text{ is the identity matrix of size } m \\times m.\n",
    "$$\n",
    "\n",
    "You **don't** need to do this for $K_*$ and $K_{**}$.\n",
    "\n",
    "#### Exercise 2.4.1\n",
    "\n",
    "First, implement the `K` property of the `GPR` class. It should return the covariance matrix $K$ of the training data. \n",
    "\n",
    "Then, implement the `predict` method of the `GPR` class below. The argument `x` is a vector of the test points, and the method should return:\n",
    "- the mean $\\mu$,\n",
    "- the covariance matrix $\\Sigma$, and\n",
    "- the variance $\\sigma^2$ of the posterior distribution at the test points.\n",
    "\n",
    "Note that, the training data and a **general calculator** for covariance matrices $K(\\mathbf{x^{(1)}}, \\mathbf{x^{(2)}})$ are provided as \n",
    "instance attributes of the `GPR` class. It may also be a good idea to avoid recalculating the covariance matrix $K$ every time you make a \n",
    "prediction.\n",
    "\n",
    "**Important**: Actually inverting the matrix $K$ is not recommended, as it is computationally expensive, as well as numerically unstable. Instead,\n",
    "whenever you need to calculate $K^{-1} ...$, use the provided `solve(A, B)` function, which solves the linear system $AX = B$ for $X$. It also works\n",
    "for multiple right-hand sides (i.e. $B$ can be a matrix).\n",
    "\n",
    "Tip: `@` or `np.dot` can be used for matrix multiplication.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> The recipe for the prediction process is as follows:\n",
    "> \n",
    "> 1. Calculate the covariance matrix $K_* = K(\\mathbf{x_{\\text{train}}}, \\mathbf{x})$ between the training points and the test points.\n",
    "> 2. Calculate the covariance matrix $K_{**} = K(\\mathbf{x}, \\mathbf{x})$ between the test points themselves.\n",
    "> 3. Calculate the mean of the posterior distribution $\\mu = K_* K^{-1} y$, where $y$ is the vector of training values.\n",
    "> 4. Calculate the covariance of the posterior distribution $\\Sigma = K_{**} - K_* K^{-1} K_*^T$.\n",
    "> 5. The variance of the posterior distribution is just the diagonal of the covariance matrix $\\Sigma$.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary> Note </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> In practical implementations of GPR you will face several numerical problems. For example, numeric approximations made during \n",
    "> matrix operations may lead to a non-invertible/non-positive-semi-definite covariance matrix $\\Sigma$. This is, however, not\n",
    "> a valid covariance matrix for a Gaussian distribution, which makes further calculations impossible. To circumvent this issue,\n",
    "> we later add a small value to the diagonal of the covariance matrix to ensure it is positive semi-definite.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bca0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import cg, spilu, LinearOperator\n",
    "\n",
    "\n",
    "def incomplete_cholesky_preconditioner(A: Matrix) -> LinearOperator:\n",
    "    \"\"\"Compute the Incomplete Cholesky preconditioner for matrix A.\"\"\"\n",
    "    A_csc = csc_matrix(A)\n",
    "    ilu = spilu(A_csc, drop_tol=1e-5)\n",
    "\n",
    "    M = LinearOperator(A.shape, ilu.solve)\n",
    "    return M\n",
    "\n",
    "\n",
    "def solve(\n",
    "    A: Matrix,\n",
    "    B: Vector | Matrix,\n",
    "    /,\n",
    "    *,\n",
    "    tolerance: float = 1e-10,\n",
    "    max_iterations: int | None = None,\n",
    ") -> Vector | Matrix:\n",
    "    \"\"\"Solves AX = B for X using the Conjugate Gradient method, where A is symmetric positive definite.\"\"\"\n",
    "    if not isinstance(B, np.ndarray):\n",
    "        B = np.array(B)\n",
    "\n",
    "    if A.shape[0] == 1:\n",
    "        return np.array([(B / A).squeeze()])\n",
    "\n",
    "    if B.ndim == 1:\n",
    "        B = B.reshape(-1, 1)\n",
    "\n",
    "    N, nrhs = B.shape\n",
    "    solutions: list[Vector] = []\n",
    "\n",
    "    max_iterations = max_iterations or N\n",
    "    M = incomplete_cholesky_preconditioner(A)\n",
    "\n",
    "    for i in range(nrhs):\n",
    "        x, info = cg(A, B[:, i], M=M, rtol=tolerance, maxiter=max_iterations)\n",
    "        if info > 0:\n",
    "            # print(f\"Warning: CG did not converge for column {i}. Error code: {info}\")\n",
    "            pass  # You can uncomment the above line if you want to see the warning\n",
    "\n",
    "        solutions.append(x)\n",
    "\n",
    "    return np.array(solutions).squeeze().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da38636",
   "metadata": {},
   "source": [
    "Some useful classes/interfaces are provided below to help you with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4d1fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovarianceMatrixCalculator(Protocol):\n",
    "    def __call__(self, x_1: Vector, x_2: Vector) -> Matrix:\n",
    "        \"\"\"Calculates the covariance matrix for the given input vectors x_1 and x_2.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingData:\n",
    "    x: Vector\n",
    "    y: Vector\n",
    "\n",
    "    def take(self, count: int) -> \"TrainingData\":\n",
    "        \"\"\"Returns new training data with only the first `count` data points.\"\"\"\n",
    "        return TrainingData(x=self.x[:count], y=self.y[:count])\n",
    "\n",
    "    @property\n",
    "    def m(self) -> int:\n",
    "        \"\"\"Returns the number of training examples.\"\"\"\n",
    "        return len(self.y)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PredictionResults:  # This should be the output of the predict method\n",
    "    _: KW_ONLY\n",
    "    mean: Vector\n",
    "    covariance: Matrix\n",
    "    variance: Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "867d9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class OneDimensionalCovarianceMatrixCalculator:\n",
    "    kernel: Kernel\n",
    "\n",
    "    def __call__(self, x_1: Vector, x_2: Vector) -> Matrix:\n",
    "        return covariance_matrix(x_1, x_2, self.kernel)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9bdfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPR:\n",
    "    training: TrainingData\n",
    "    covariance_matrix: CovarianceMatrixCalculator\n",
    "    sigma_noise: float\n",
    "\n",
    "    # {% if exercise['2.4.1'].solution %}\n",
    "    _K: Matrix | None = None  # We can cache the covariance matrix like this\n",
    "    # {% else %}\n",
    "    # Did you know you can use instance attributes to store computation results?\n",
    "    # {% endif %}\n",
    "\n",
    "    @property\n",
    "    def K(self) -> Matrix:\n",
    "        # You can use this as the noise term in the covariance matrix\n",
    "        noise = max(self.sigma_noise, 3e-7) * np.identity(self.training.m)\n",
    "\n",
    "        # {% if exercise['2.4.1'].solution %}\n",
    "        # TODO: Review me!\n",
    "        if self._K is None:\n",
    "            self._K = self.covariance_matrix(self.training.x, self.training.x) + noise\n",
    "\n",
    "        return self._K\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        # {% endif %}\n",
    "\n",
    "    def predict(self, x: Vector) -> PredictionResults:\n",
    "        # {% if exercise['2.4.1'].solution %}\n",
    "        # TODO: Review me!\n",
    "        # We first calculate the covariance between the training points and the new points\n",
    "        K_star = self.covariance_matrix(self.training.x, x)\n",
    "\n",
    "        # Then we calculate the covariance between the new points\n",
    "        K_double_star = self.covariance_matrix(x, x)\n",
    "\n",
    "        # Next, we calculate the mean and covariance of the prediction\n",
    "        mean = K_star @ solve(self.K, self.training.y)\n",
    "        covariance = K_double_star - K_star @ solve(self.K, K_star.T)\n",
    "\n",
    "        # Finally, we add a value larger than machine epsilon to ensure the covariance is SPD\n",
    "        covariance = covariance + 3e-5 * np.ones(np.shape(covariance)[0])\n",
    "\n",
    "        return PredictionResults(\n",
    "            mean=mean, covariance=covariance, variance=np.diag(covariance)\n",
    "        )\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "\n",
    "        # Add a value larger than machine epsilon to ensure the covariance is SPD, like this:\n",
    "        # covariance = covariance + 3e-5 * np.ones(np.shape(covariance)[0])\n",
    "\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    @staticmethod\n",
    "    def create(\n",
    "        training_data: TrainingData, kernel: Kernel, *, sigma_noise: float = 0\n",
    "    ) -> \"GPR\":\n",
    "        \"\"\"Creates a new Gaussian Process Regression model from the given training data and kernel.\"\"\"\n",
    "        return GPR(\n",
    "            training_data,\n",
    "            OneDimensionalCovarianceMatrixCalculator(kernel),\n",
    "            sigma_noise=sigma_noise,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe426230",
   "metadata": {},
   "source": [
    "### 2.5. Visualizing the GPR\n",
    "\n",
    "The typical way to visualize the predictions of a GPR model is to plot the mean of the posterior distribution, along with the standard deviation. Let's\n",
    "do exactly that.\n",
    "\n",
    "#### Exercise 2.5.1\n",
    "\n",
    "Use the `plot_GPR` function provided below, along with the sample training and test data, to visualize the predictions of the GPR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b99b06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_traces_for(\n",
    "    model: GPR,\n",
    "    x: Vector,\n",
    "    *,\n",
    "    show_mean: bool = True,\n",
    "    show_samples: bool = True,\n",
    "    show_variance: bool = True,\n",
    ") -> list[Scatter]:\n",
    "    result = model.predict(x)\n",
    "    mean = result.mean\n",
    "    standard_deviation = np.sqrt(result.variance)\n",
    "\n",
    "    data: list[Scatter] = []\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        data.append(\n",
    "            uncertainty_area_scatter(\n",
    "                x=x,\n",
    "                y_lower=mean - i * standard_deviation,\n",
    "                y_upper=mean + i * standard_deviation,\n",
    "                name=f\"Mean +/- {i} * Standard Deviation\",\n",
    "                visible=show_variance,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    data.append(line_scatter(x=x, y=mean, visible=show_mean))\n",
    "    data.append(\n",
    "        dot_scatter(x=model.training.x, y=model.training.y, visible=show_samples)\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_GPR(\n",
    "    model: GPR,\n",
    "    x: Vector,\n",
    "    *,\n",
    "    additional_traces: Sequence[Scatter] = (),\n",
    "    show_mean: bool = True,\n",
    "    show_samples: bool = True,\n",
    "    show_variance: bool = True,\n",
    ") -> None:\n",
    "    data = create_traces_for(\n",
    "        model,\n",
    "        x,\n",
    "        show_mean=show_mean,\n",
    "        show_samples=show_samples,\n",
    "        show_variance=show_variance,\n",
    "    )\n",
    "\n",
    "    set_layout_for(\n",
    "        Figure(data=[*data, *additional_traces]),\n",
    "        title=f\"GPR with kernel {model.covariance_matrix} and {model.sigma_noise if model.sigma_noise else 'no'} noise\",\n",
    "        x_title=\"x\",\n",
    "        y_title=\"f(x)\",\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e13531",
   "metadata": {},
   "source": [
    "Here's your sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58af6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary training values for demonstration purposes\n",
    "training_data = TrainingData(\n",
    "    x=np.array([0, 0.3, 1, 3.1, 4.7]),\n",
    "    y=np.array([1, 0, 1.4, 1, -0.9]),\n",
    ")\n",
    "\n",
    "# these are our test points\n",
    "x = np.arange(-1, 10, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951188c",
   "metadata": {},
   "source": [
    "You can use `GPR.create` to create a GPR model with a given kernel and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {% if not exercise['2.5.1'].solution %}\n",
    "# TODO: Implement me!\n",
    "print(\"Oops! Looks like you forgot to implement this cell.\")\n",
    "# {% else %}\n",
    "# TODO: Review me!\n",
    "model = GPR.create(training_data, RBFKernel())\n",
    "plot_GPR(model, x)\n",
    "# {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409d823",
   "metadata": {},
   "source": [
    "### 2.6. Reflection\n",
    "\n",
    "As you can see, a cool feature of the GPR is that it is sort of a probability distribution over functions - that means can literally \"draw\" random functions\n",
    "from the distribution.\n",
    "\n",
    "- What do you think a random function drawn from the GPR distribution looks like?\n",
    "- Does the function always pass through the training points?\n",
    "- How do the hyperparameters of the kernel function affect the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2429ba6",
   "metadata": {},
   "source": [
    "Once you're done thinking, you can try it by running the next cell and pressing the \"Add random drawing\" button multiple times. \n",
    "\n",
    "Now compare it with the grey standard deviation areas. The \"density\" of the functions will correspond to the greyness of these \n",
    "areas, but be careful! **Not every function of the distribution must be contained in the visualized uncertainty areas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class RandomDrawingGenerator:\n",
    "    result: PredictionResults\n",
    "    x: Vector\n",
    "\n",
    "    def __call__(self, figure: Figure) -> None:\n",
    "        figure.add_trace(\n",
    "            line_scatter(\n",
    "                x=self.x,\n",
    "                y=np.random.multivariate_normal(\n",
    "                    self.result.mean, self.result.covariance\n",
    "                ),\n",
    "                name=\"random function\",\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def interactive_random_functions_figure(\n",
    "    training: TrainingData, kernel: Kernel, x: Vector\n",
    ") -> Figure:\n",
    "    model = GPR.create(training, kernel)\n",
    "    draw_random_function = RandomDrawingGenerator(model.predict(x), x)\n",
    "\n",
    "    return interactive_figure(\n",
    "        data=create_traces_for(model, x, show_mean=False),\n",
    "        title=f\"Random functions of the Gaussian process with {kernel}\",\n",
    "        x_title=\"x\",\n",
    "        y_title=\"f(x)\",\n",
    "        buttons=[Button(\"Add random function\", on_click=draw_random_function)],\n",
    "    )\n",
    "\n",
    "\n",
    "interactive_random_functions_figure(training_data, RBFKernel(), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b96b3",
   "metadata": {},
   "source": [
    "### 2.7. (Bonus) Different Kernel Functions\n",
    "\n",
    "The RBF kernel is just one of many kernel functions that can be used in GPR. Here are a few more:\n",
    " \n",
    "- **Linear Kernel**: $k_{\\text{Lin}}(x, x') = \\sigma_b^2 + \\sigma_v^2 (x - c)(x' - c)$\n",
    "- **Periodic Kernel**: $k_{\\text{Per}}(x, x') = \\sigma^2 \\exp\\left(-\\dfrac{2\\sin^2(\\pi|x - x'|/p)}{l^2}\\right)$\n",
    "- **Ration Quadratic Kernel**: $k_{\\text{RQ}}(x, x') = \\sigma^2 \\left(1 + \\dfrac{(x - x')^2}{2\\alpha l^2}\\right)^{-\\alpha}$\n",
    "\n",
    "#### Exercise 2.7.1\n",
    "\n",
    "Implement the periodic kernel below and see what impact it has on the predictions. You can implement the other kernels as well if you're \n",
    "feeling adventurous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa34c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class PeriodicKernel:\n",
    "    sigma: float = 0.4\n",
    "    length: float = 1\n",
    "\n",
    "    def __call__(self, x_1: float, x_2: float) -> float:\n",
    "        # {% if exercise['2.7.1'].solution %}\n",
    "        # TODO: Review me!\n",
    "        return float(\n",
    "            self.sigma**2\n",
    "            * np.exp(-2 * np.sin((np.pi * np.abs(x_1 - x_2) / 2)) ** 2 / self.length**2)\n",
    "        )\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "\n",
    "interactive_random_functions_figure(training_data, PeriodicKernel(), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ee73f",
   "metadata": {},
   "source": [
    "### 2.8. Reflection\n",
    "\n",
    "Okay, now think about this:\n",
    "- What would happen if the points in the training data were very close to each other?\n",
    "- What would happen if the points in the training data were very far apart?\n",
    "- What if we had more training data points? what about less?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "Now that we've seen what a big difference the choice of the kernel can make, we demonstrate on how the predicted results change, as we iteratively add more observed points to the GPR. Click the \"Add data point\" button to see the results change each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36354bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingDataUpdater:\n",
    "    training_data: TrainingData\n",
    "    kernel: Kernel\n",
    "    x: Vector\n",
    "    point_count: int = 1  # Does not work with 1 point for some reason\n",
    "\n",
    "    def add(self, figure: Figure) -> None:\n",
    "        self.point_count = min(self.point_count + 1, len(self.training_data.x))\n",
    "        self.update(figure)\n",
    "\n",
    "    def remove(self, figure: Figure) -> None:\n",
    "        self.point_count = max(1, self.point_count - 1)\n",
    "        self.update(figure)\n",
    "\n",
    "    def update(self, figure: Figure) -> None:\n",
    "        traces = self.traces()\n",
    "\n",
    "        # This is very hacky, but it works for now.\n",
    "        figure.data[3].y = traces[-2].y  # mean\n",
    "        figure.data[4].x = traces[-1].x  # new x values\n",
    "        figure.data[4].y = traces[-1].y  # new y values\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            figure.data[i - 1].y = traces[i - 1].y  # uncertainty areas\n",
    "\n",
    "    def traces(self) -> list[Scatter]:\n",
    "        training_data = self.training_data.take(self.point_count)\n",
    "        model = GPR.create(training_data, self.kernel)\n",
    "        return create_traces_for(model, self.x)\n",
    "\n",
    "\n",
    "update_data_points = TrainingDataUpdater(training_data, RBFKernel(), x)\n",
    "\n",
    "interactive_figure(\n",
    "    data=update_data_points.traces(),\n",
    "    title=\"GPR with varying number of training points\",\n",
    "    x_title=\"x\",\n",
    "    y_title=\"f(x)\",\n",
    "    buttons=[\n",
    "        Button(\"Add data point\", on_click=update_data_points.add),\n",
    "        Button(\"Remove data point\", on_click=update_data_points.remove),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17146a",
   "metadata": {},
   "source": [
    "## 2.9 Visualization of effect of free parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e03650",
   "metadata": {},
   "source": [
    "### 2.9 Reflection\n",
    "Awesome! Now that we can make predictions with our GPR, lets visualize how the GPR changes if we change the free parameters, i.e. length-scale, variance and white noise. As you will see, these parameters have a huge impact on the predicted function and we'll optimize for them in the last exercise task.\n",
    "\n",
    "Ask yourself the following: What impact on the predicted function does each one of the hyperparameters have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class HyperparameterUpdater:\n",
    "    training_data: TrainingData\n",
    "    x: Vector\n",
    "\n",
    "    def __call__(self, figure: Figure, sigma: float, l: float, noise: float) -> None:\n",
    "        data = self.plot(sigma, l, noise)\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            figure.data[i].y = data[i].y\n",
    "\n",
    "    def plot(self, sigma: float, l: float, noise: float) -> list[Scatter]:\n",
    "        kernel = RBFKernel(sigma=sigma, l=l)\n",
    "        model = GPR.create(self.training_data, kernel, sigma_noise=noise)\n",
    "        return create_traces_for(model, self.x)\n",
    "\n",
    "\n",
    "update_hyperparameters = HyperparameterUpdater(training_data, x)\n",
    "\n",
    "interactive_figure(\n",
    "    data=update_hyperparameters.plot(1, 0.5, 0.1),\n",
    "    title=\"GPR with varying hyperparameters and noise\",\n",
    "    x_title=\"x\",\n",
    "    y_title=\"f(x)\",\n",
    "    sliders=[\n",
    "        Slider(\n",
    "            \"sigma\",\n",
    "            min=0.01,\n",
    "            max=3,\n",
    "            step=0.01,\n",
    "            default=1,\n",
    "            description=r\"Signal variance (sigma)\",\n",
    "        ),\n",
    "        Slider(\n",
    "            \"l\",\n",
    "            min=0.01,\n",
    "            max=3,\n",
    "            step=0.01,\n",
    "            default=0.5,\n",
    "            description=r\"Length scale (l)\",\n",
    "        ),\n",
    "        Slider(\n",
    "            \"noise\",\n",
    "            min=0,\n",
    "            max=0.5,\n",
    "            step=0.025,\n",
    "            default=0.1,\n",
    "            description=r\"Noise\",\n",
    "        ),\n",
    "    ],\n",
    "    on_update=update_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "Pretty impressive how many function 'shapes' we can generate with a GPR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 2.10. Optimization of Hyperparameters\n",
    "\n",
    "There's one more thing we can do to improve the predictions of our GPR model: optimize the hyperparameters of the kernel function. A\n",
    "typical approach is to maximize the log-likelihood of the training data given the hyperparameters. The log-likelihood is given by:\n",
    "\n",
    "$$\n",
    "\\log p(y | X, \\theta) = -\\frac{1}{2} y^T K^{-1} y - \\frac{1}{2} \\log |K| - \\frac{m}{2} \\log 2\\pi\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $y$ is the vector of training values,\n",
    "- $X$ is the matrix of training points,\n",
    "- $K$ is the covariance matrix between the training points,\n",
    "- $m$ is the number of training points, and\n",
    "- $\\theta$ is the vector of hyperparameters.\n",
    "\n",
    "#### Exercise 2.10.1\n",
    "\n",
    "Implement the `optimize_hyperparameters` function below, which takes the following arguments:\n",
    "- `create_model`: a function that creates a GPR model from the given hyperparameters,\n",
    "- `theta_0`: the initial guess for the hyperparameters, and\n",
    "- `bounds`: the bounds for the hyperparameters.\n",
    "\n",
    "The function should return the optimized hyperparameters as a `Vector` of the same size as `theta_0`. You can use the `K` property of the GPR\n",
    "class you implemented earlier to calculate the covariance matrix.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> The optimization problem can be solved using the `minimize` function from the `scipy.optimize` module. You can use the `L-BFGS-B` method\n",
    "> for the optimization. Pay attention that the `minimize` function minimizes the objective function, and not maximizes it.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "Bounds: TypeAlias = tuple[float | None, float | None]\n",
    "\n",
    "\n",
    "class ModelCreator(Protocol):\n",
    "    def __call__(self, theta: Vector) -> GPR:\n",
    "        \"\"\"Creates a GPR model with the given hyperparameters.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "def optimize_hyperparameters(\n",
    "    create_model: ModelCreator,\n",
    "    theta_0: Vector,\n",
    "    bounds: list[Bounds],\n",
    ") -> Vector:\n",
    "    # {% if exercise['2.10.1'].solution %}\n",
    "    # TODO: Review me!\n",
    "    def objective(theta: Vector) -> float:\n",
    "        model = create_model(theta)\n",
    "        y = model.training.y\n",
    "        m = model.training.m\n",
    "\n",
    "        L = (\n",
    "            y.T @ solve(model.K, y)\n",
    "            + np.log(np.linalg.det(model.K))\n",
    "            + m * np.log(2 * np.pi)\n",
    "        ) / 2\n",
    "\n",
    "        return L\n",
    "\n",
    "    return minimize(\n",
    "        lambda x: objective(x), x0=theta_0, bounds=bounds, method=\"L-BFGS-B\"\n",
    "    ).x\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "source": [
    "Let's see the difference in the predictions before and after optimizing the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class GPRWithRBFKernelCreator:  # This is our ModelCreator\n",
    "    training_data: TrainingData\n",
    "    sigma_noise: float\n",
    "\n",
    "    def __call__(self, theta: Vector) -> GPR:\n",
    "        sigma, l = theta\n",
    "        return GPR.create(\n",
    "            self.training_data,\n",
    "            RBFKernel(sigma=sigma, l=l),\n",
    "            sigma_noise=self.sigma_noise,\n",
    "        )\n",
    "\n",
    "\n",
    "# Some arbitrary function that we want to approximate\n",
    "def mollifier(x: Vector) -> Vector:\n",
    "    return 5.0 * np.exp(-((x - 3) ** 2) / (2 * 2**2))\n",
    "\n",
    "\n",
    "# Arbitrary data points, we also add some noise to the actual function values\n",
    "sigma_noise = 0.25\n",
    "x_training = np.array([-0.75, 0.25, 2.9, 5.0, 5.5, 6.0, 10.0])\n",
    "y_training = mollifier(x_training) + np.random.normal(0, sigma_noise, len(x_training))\n",
    "training_data = TrainingData(x=x_training, y=y_training)\n",
    "\n",
    "# We create a range of x values for testing/plotting\n",
    "x = np.linspace(-1, 11, 100)\n",
    "y = mollifier(x)\n",
    "theta_0 = np.array([1.0, 1.0])\n",
    "\n",
    "# Let's plot the actual function\n",
    "actual_function_trace = line_scatter(\n",
    "    x=x, y=y, name=\"Actual function\", color=\"green\", dash=\"dash\"\n",
    ")\n",
    "\n",
    "model_creator = GPRWithRBFKernelCreator(training_data, sigma_noise)\n",
    "\n",
    "# We first plot the GPR with the initial hyperparameters\n",
    "print(\"First, with the initial hyperparameters:\")\n",
    "plot_GPR(model_creator(theta_0), x=x, additional_traces=[actual_function_trace])\n",
    "\n",
    "# Now we optimize the hyperparameters\n",
    "theta = optimize_hyperparameters(\n",
    "    model_creator, theta_0, bounds=[(0.01, None), (0.01, None)]\n",
    ")\n",
    "\n",
    "# Finally, we plot the GPR with the optimized hyperparameters\n",
    "print(\"Then, with the optimized hyperparameters:\")\n",
    "plot_GPR(model_creator(theta), x=x, additional_traces=[actual_function_trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "### 2.11. Multi-dimensional Inputs\n",
    "\n",
    "So far, we've only been working with one-dimensional inputs. However, GPR can be extended to multiple dimensions. Everything stays\n",
    "pretty much the same, except that the kernel function is now a product of the one-dimensional kernels for each dimension.\n",
    "\n",
    "$$\n",
    "k_{\\text{multi}}(x, x') = \\prod_{i=1}^n k_i(x_i, x_i')\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x = (x_1, x_2, \\ldots, x_n)$ and $x' = (x_1', x_2', \\ldots, x_n')$ are the input vectors,\n",
    "- $k_i$ is the kernel function for the $i$-th dimension, and\n",
    "- $n$ is the number of dimensions.\n",
    "\n",
    "#### Exercise 2.11.1\n",
    "\n",
    "Implement the `MultiDimensionalKernel` class below, which takes a list of one-dimensional kernel functions and returns their \n",
    "combined kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDimensionalKernel:\n",
    "    kernels: list[Kernel]\n",
    "\n",
    "    def __init__(self, *kernels: Kernel) -> None:\n",
    "        self.kernels = list(kernels)\n",
    "\n",
    "    def __call__(self, x_1: Vector, x_2: Vector) -> float:\n",
    "        # {% if exercise['2.11.1'].solution %}\n",
    "        # TODO: Review me!\n",
    "        result = 1\n",
    "\n",
    "        for kernel, x_1_i, x_2_i in zip(self.kernels, x_1, x_2):\n",
    "            result *= kernel(x_1_i, x_2_i)\n",
    "\n",
    "        return result\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \" * \".join(str(kernel) for kernel in self.kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d4a93",
   "metadata": {},
   "source": [
    "#### Exercise 2.11.2\n",
    "\n",
    "Another detail to consider is that the way we calculate the covariance matrix changes. Instead of having $\\mathbf{x^{(1)}}$ and $\\mathbf{x^{(2)}}$,\n",
    "as vectors of points, we now have matrices $\\mathbf{X^{(1)}}$ and $\\mathbf{X^{(2)}}$. Each row of these matrices represents a point in the\n",
    "corresponding n-dimensional space.\n",
    "\n",
    "Implement the `multi_dimensional_covariance_matrix` function below, which takes two matrices of training points $\\mathbf{X^{(1)}}$ and $\\mathbf{X^{(2)}}$,\n",
    "and the multi-dimensional kernel function. It should return the covariance matrix $K(\\mathbf{X^{(1)}}, \\mathbf{X^{(2)}})$.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> This task is much simpler than it sounds. You need to do the exact same thing as before, but instead of calculating the kernel function\n",
    "> for each pair of points, you calculate it for each pair of rows. The kernel function can already handle pairs of vectors as inputs.\n",
    ">\n",
    "> If you implemented the one-dimensional covariance matrix correctly, it could directly work for the multi-dimensional case as well.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b83254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_dimensional_covariance_matrix(\n",
    "    x_1: Matrix, x_2: Matrix, kernel: MultiDimensionalKernel\n",
    ") -> Matrix:\n",
    "    # {% if exercise['2.11.2'].solution %}\n",
    "    # TODO: Review me!\n",
    "    return np.array([[kernel(a, b) for a in x_1] for b in x_2])\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class MultiDimensionalCovarianceMatrixCalculator:\n",
    "    kernel: MultiDimensionalKernel\n",
    "\n",
    "    def __call__(self, x_1: Matrix, x_2: Matrix) -> Matrix:\n",
    "        return multi_dimensional_covariance_matrix(x_1, x_2, self.kernel)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f10f8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_3d_layout_for(\n",
    "    figure: go.Figure,\n",
    "    *,\n",
    "    title: str,\n",
    "    x_title: str = \"X\",\n",
    "    y_title: str = \"Y\",\n",
    "    z_title: str = \"Z\",\n",
    ") -> go.Figure:\n",
    "    figure.update_layout(\n",
    "        height=800,\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis_title=x_title,\n",
    "            yaxis_title=y_title,\n",
    "            zaxis_title=z_title,\n",
    "        ),\n",
    "        legend=dict(yanchor=\"top\", y=1.05, xanchor=\"right\", x=1.05),\n",
    "    )\n",
    "    return figure\n",
    "\n",
    "\n",
    "def surface_scatter(\n",
    "    x: Matrix,\n",
    "    y: Matrix,\n",
    "    z: Matrix,\n",
    "    *,\n",
    "    name: str = \"Prediction\",\n",
    "    color_scale: str = \"Plasma\",\n",
    "    opacity: float = 1.0,\n",
    "    color: str | None = None,\n",
    "    visible: bool = True,\n",
    "    showlegend: bool = True,\n",
    "    legend_only: bool = False,\n",
    ") -> go.Surface:\n",
    "    actual_colorscale = color_scale if color is None else [[0, color], [1, color]]\n",
    "\n",
    "    return go.Surface(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        name=name,\n",
    "        visible=\"legendonly\" if legend_only else visible,\n",
    "        showlegend=showlegend,\n",
    "        colorscale=actual_colorscale,\n",
    "        opacity=opacity,\n",
    "        showscale=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def dot_scatter_3d(\n",
    "    x: Vector,\n",
    "    y: Vector,\n",
    "    z: Vector,\n",
    "    *,\n",
    "    name: str = \"Observed points\",\n",
    "    color: str = \"red\",\n",
    "    visible: bool = True,\n",
    "    showlegend: bool = True,\n",
    ") -> go.Scatter3d:\n",
    "    return go.Scatter3d(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        name=name,\n",
    "        visible=visible,\n",
    "        showlegend=showlegend,\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=color, size=5),\n",
    "    )\n",
    "\n",
    "\n",
    "def uncertainty_volume(\n",
    "    x: Matrix,\n",
    "    y: Matrix,\n",
    "    z_lower: Matrix,\n",
    "    z_upper: Matrix,\n",
    "    *,\n",
    "    name: str = \"Uncertainty Volume\",\n",
    "    opacity: float = 0.3,\n",
    "    visible: bool = True,\n",
    "    showlegend: bool = True,\n",
    ") -> list[go.Surface]:\n",
    "    lower_surface = go.Surface(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z_lower,\n",
    "        name=name + \" (lower bound)\",\n",
    "        visible=visible,\n",
    "        showlegend=showlegend,\n",
    "        legendgroup=name,\n",
    "        colorscale=\"Blues\",\n",
    "        opacity=opacity,\n",
    "        showscale=False,\n",
    "    )\n",
    "    upper_surface = go.Surface(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z_upper,\n",
    "        name=name + \" (upper bound)\",\n",
    "        visible=visible,\n",
    "        showlegend=showlegend,\n",
    "        legendgroup=name,\n",
    "        colorscale=\"Reds\",\n",
    "        opacity=opacity,\n",
    "        showscale=False,\n",
    "    )\n",
    "    return [lower_surface, upper_surface]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfa08c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_grid(\n",
    "    x_range: tuple[float, float], y_range: tuple[float, float], m: int\n",
    ") -> Matrix:\n",
    "    points_per_dimension = int(np.sqrt(m))\n",
    "    x_0, x_f = x_range\n",
    "    y_0, y_f = y_range\n",
    "    delta_x = (x_f - x_0) / points_per_dimension\n",
    "    delta_y = (y_f - y_0) / points_per_dimension\n",
    "\n",
    "    x = np.arange(x_0, x_f + delta_x, delta_x)\n",
    "    y = np.arange(y_0, y_f + delta_y, delta_y)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Flatten and stack the grid to form the matrix\n",
    "    return np.column_stack([X.ravel(), Y.ravel()])\n",
    "\n",
    "\n",
    "def input_to_grid(x: Matrix) -> tuple[Matrix, Matrix]:\n",
    "    # Separate x and y coordinates\n",
    "    x_coordinates = x[:, 0]\n",
    "    y_coordinates = x[:, 1]\n",
    "\n",
    "    # Find unique values\n",
    "    x_unique = np.unique(x_coordinates)\n",
    "    y_unique = np.unique(y_coordinates)\n",
    "\n",
    "    # Create meshgrid\n",
    "    X, Y = np.meshgrid(x_unique, y_unique)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def output_to_grid(*, x: Vector, y: Vector, z: Vector, X: Matrix, Y: Matrix) -> Matrix:\n",
    "    # Initialize Z with NaN values\n",
    "    Z = np.full(X.shape, np.nan)\n",
    "\n",
    "    # Fill in Z values where we have data\n",
    "    for x_k, y_k, z_k in zip(x, y, z):\n",
    "        i = np.where(X[0, :] == x_k)[0][0]\n",
    "        j = np.where(Y[:, 0] == y_k)[0][0]\n",
    "        Z[j, i] = z_k\n",
    "\n",
    "    return Z\n",
    "\n",
    "\n",
    "def create_surface(\n",
    "    x: Matrix,\n",
    "    f: Callable[[Matrix], Vector],\n",
    "    *,\n",
    "    name: str,\n",
    "    color: str,\n",
    "    opacity: float,\n",
    "    legend_only: bool = False,\n",
    ") -> go.Surface:\n",
    "    X, Y = input_to_grid(x)\n",
    "    Z = f(x).reshape(X.shape)\n",
    "\n",
    "    return surface_scatter(\n",
    "        x=X, y=Y, z=Z, name=name, color=color, opacity=opacity, legend_only=legend_only\n",
    "    )\n",
    "\n",
    "\n",
    "def create_traces_for_3d(\n",
    "    model: GPR,\n",
    "    x: Matrix,\n",
    "    *,\n",
    "    show_mean: bool = True,\n",
    "    show_samples: bool = True,\n",
    "    show_variance: bool = True,\n",
    ") -> list[go.Surface]:\n",
    "    X, Y = input_to_grid(x)\n",
    "\n",
    "    result = model.predict(x)\n",
    "    mean = result.mean\n",
    "    standard_deviation = np.sqrt(result.variance)\n",
    "\n",
    "    data: list[go.Surface] = []\n",
    "\n",
    "    if show_variance:\n",
    "        for i in range(1, 4):\n",
    "            lower_surface, upper_surface = uncertainty_volume(\n",
    "                x=X,\n",
    "                y=Y,\n",
    "                z_lower=(mean - i * standard_deviation).reshape(X.shape),\n",
    "                z_upper=(mean + i * standard_deviation).reshape(X.shape),\n",
    "                name=f\"Mean +/- {i} * Standard Deviation\",\n",
    "                opacity=0.3 / i,\n",
    "            )\n",
    "            data.extend([lower_surface, upper_surface])\n",
    "\n",
    "    if show_mean:\n",
    "        data.append(\n",
    "            surface_scatter(x=X, y=Y, z=mean.reshape(X.shape), name=\"Mean Prediction\")\n",
    "        )\n",
    "\n",
    "    if show_samples:\n",
    "        data.append(\n",
    "            dot_scatter_3d(\n",
    "                x=model.training.x[:, 0],\n",
    "                y=model.training.x[:, 1],\n",
    "                z=model.training.y,\n",
    "                name=\"Training Data\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_GPR_3d(\n",
    "    model: GPR,\n",
    "    x: Matrix,\n",
    "    *,\n",
    "    additional_traces: Sequence[go.Surface] = (),\n",
    "    show_mean: bool = True,\n",
    "    show_samples: bool = True,\n",
    "    show_variance: bool = True,\n",
    ") -> None:\n",
    "    data = create_traces_for_3d(\n",
    "        model,\n",
    "        x,\n",
    "        show_mean=show_mean,\n",
    "        show_samples=show_samples,\n",
    "        show_variance=show_variance,\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[*data, *additional_traces])\n",
    "\n",
    "    set_3d_layout_for(\n",
    "        fig,\n",
    "        title=f\"GPR with kernel {model.covariance_matrix} and {model.sigma_noise if model.sigma_noise else 'no'} noise\",\n",
    "        x_title=\"x\",\n",
    "        y_title=\"y\",\n",
    "        z_title=\"f(x,y)\",\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87620337",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class MultiDimensionalGPRCreator:  # This ModelCreator works with multi-dimensional kernels\n",
    "    training_data: TrainingData\n",
    "    sigma_noise: float\n",
    "\n",
    "    def __call__(self, theta: Vector) -> GPR:\n",
    "        # The theta vector looks like this: [sigma_1, l_1, sigma_2, l_2, ...]\n",
    "        # The `theta.reshape(-1, 2)` basically pairs up successive elements in the theta vector.\n",
    "        kernel = MultiDimensionalKernel(\n",
    "            *(RBFKernel(sigma=sigma, l=l) for sigma, l in theta.reshape(-1, 2))\n",
    "        )\n",
    "\n",
    "        return GPR(\n",
    "            self.training_data,\n",
    "            MultiDimensionalCovarianceMatrixCalculator(kernel),\n",
    "            sigma_noise=self.sigma_noise,\n",
    "        )\n",
    "\n",
    "\n",
    "def mollifier_3d(x: Matrix) -> Vector:\n",
    "    c_x = 3\n",
    "    c_y = 4\n",
    "    w_x = 2\n",
    "    w_y = 3\n",
    "\n",
    "    return (\n",
    "        5.0\n",
    "        * np.exp(-((x[:, 0] - c_x) ** 2 / (2 * w_x**2)))\n",
    "        * np.exp(-((x[:, 1] - c_y) ** 2 / (2 * w_y**2)))\n",
    "    )\n",
    "\n",
    "\n",
    "def noise_3d(x: Matrix) -> Vector:\n",
    "    return np.random.normal(0, sigma_noise, len(x))\n",
    "\n",
    "\n",
    "# Again, we first take some arbitrary data points and add noise\n",
    "sigma_noise = 0.25\n",
    "x_training = np.array(\n",
    "    [\n",
    "        [-0.75, 2.6, 2.9, 5.0, 5.5, 6.0, 10.0],\n",
    "        [1.0, 0.5, 3.0, 4.0, 5.0, 6.0, 7.0],\n",
    "    ],\n",
    ").T\n",
    "y_training = mollifier_3d(x_training) + noise_3d(x_training)\n",
    "training_data = TrainingData(x=x_training, y=y_training)\n",
    "\n",
    "x = input_grid((-1, 11), (0, 8), 100)\n",
    "actual_surface = create_surface(\n",
    "    x,\n",
    "    mollifier_3d,\n",
    "    name=\"Actual function\",\n",
    "    color=\"green\",\n",
    "    opacity=0.25,\n",
    "    legend_only=True,\n",
    ")\n",
    "\n",
    "theta_0 = np.array([2.4, 2.84, 2.4, 2.84])\n",
    "model_creator = MultiDimensionalGPRCreator(training_data, sigma_noise)\n",
    "\n",
    "# We first plot the GPR with the initial hyperparameters\n",
    "print(\"First, with the initial hyperparameters:\")\n",
    "plot_GPR_3d(model_creator(theta_0), x, additional_traces=[actual_surface])\n",
    "\n",
    "# Now we optimize the hyperparameters\n",
    "theta = optimize_hyperparameters(\n",
    "    model_creator,\n",
    "    theta_0,\n",
    "    bounds=[(0.01, None), (0.01, None), (0.01, None), (0.01, None)],\n",
    ")\n",
    "\n",
    "# Finally, we plot the GPR with the optimized hyperparameters\n",
    "print(\"Then, with the optimized hyperparameters:\")\n",
    "plot_GPR_3d(model_creator(theta), x, additional_traces=[actual_surface])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa4596",
   "metadata": {},
   "source": [
    "### 2.12. Reflection\n",
    "\n",
    "What do you think:\n",
    "- Is the multi-dimensional GPR able to predict the function better after optimizing the hyperparameters? What's the difference?\n",
    "- What would happen if we had more data points in the multi-dimensional case?\n",
    "- What if we used a different kernel function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## 3. GPR for Motor Temperature Prediction\n",
    "\n",
    "### 3.1. Preparing the GPR Model\n",
    "\n",
    "Back to our original problem! We have the motor temperature data, and we want to predict the temperature of the motor winding using GPR.\n",
    "\n",
    "You've probably generated some ideas on how we can use the data available to us to predict the motor winding temperature, but here's\n",
    "one way to do it:\n",
    "\n",
    "1. **Preprocess the Data**: The data is noisy, so we need to clean it up a bit. We can use a moving average filter to smooth out the data.\n",
    "2. **Extract the Features**: We can extract some parts of the data that we think are important for predicting the motor winding temperature.\n",
    "    We suggest using the following features:\n",
    "    - The starting temperature of the motor winding,\n",
    "    - The time the motor has been running, and\n",
    "    - The phase of the motor (on or off).  \n",
    "    \n",
    "    These features will comprise the 3-dimensional input vector for the GPR model. Our output data will be the temperature difference of the motor\n",
    "    winding. Throughout this process, we will also want to normalize the data to make it easier for the GPR model to learn the patterns.\n",
    "3. **Split the Data**: We can split the data into training and test sets. We can use the first 75% of the data for training and the rest for testing.\n",
    "4. **Train the GPR Model**: We can use the extracted features and the final temperature data to train (& tune the hyperparameters of) the GPR model.\n",
    "5. **Test the GPR Model**: We can use the test data to evaluate the performance of the GPR model.\n",
    "6. **Predict the Motor Winding Temperature**: Finally, we can use the trained GPR model to predict the temperature of the motor winding at any given \n",
    "    time. The controller can then use this prediction to regulate the motor activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309b91c",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.1\n",
    "\n",
    "Implement the `denoise` function given below, which takes two vectors `x` and `y`, representing the input and output data, and applies a \n",
    "moving average filter to the output data. The function should return both the new input and output vectors. \n",
    "\n",
    "When applying the filter, you may decide to discard the first and last few points of the output data, so make sure to adjust the input \n",
    "data accordingly.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> You can use the `np.convolve` function of numpy to apply the filter. Set the `mode` parameter to `'valid'` to discard the first and last few points.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3761682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(\n",
    "    x: Vector,\n",
    "    y: Vector,\n",
    "    *,\n",
    "    window_size: int,\n",
    ") -> tuple[Vector, Vector]:\n",
    "    # {% if exercise['3.1.1'].solution %}\n",
    "    # TODO: Review me!\n",
    "    x_denoised = x[window_size // 2 : -(window_size // 2)]\n",
    "    y_denoised = np.convolve(y, np.ones(window_size) / window_size, mode=\"valid\")\n",
    "\n",
    "    return x_denoised, y_denoised\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd67c1f",
   "metadata": {},
   "source": [
    "Applying our denoising function to the motor temperature data, we can now visualize the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "t_denoised, T_denoised = denoise(t, T, window_size=window_size)\n",
    "\n",
    "set_layout_for(\n",
    "    Figure(\n",
    "        data=[\n",
    "            dot_scatter(x=t, y=T, name=\"Original Noisy data\"),\n",
    "            line_scatter(x=t_denoised, y=T_denoised, name=\"Denoised data\"),\n",
    "        ]\n",
    "    ),\n",
    "    title=f\"Denoised temperature data (window size = {window_size})\",\n",
    "    x_title=\"Time\",\n",
    "    y_title=\"Temperature\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f94349d",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.2\n",
    "\n",
    "Implement the `extract_features` function below, which takes the cleaned input data and extracts the following feature vectors **for pairs of\n",
    "data points**:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\left[ x_1, x_2, x_3 \\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x_1$ is the initial temperature of the motor winding,\n",
    "- $x_2$ is the time the motor has been running, and\n",
    "- $x_3$ is the phase of the motor (on or off).\n",
    "\n",
    "Our label $y$ will be the temperature difference of the motor winding.\n",
    "\n",
    "The function should return a tuple `(X, y)` where `X` is the matrix of features and `y` is the output data. In `X`, each row represents a\n",
    "single data point, and each column represents a feature.\n",
    "\n",
    "You may be wondering how you should choose the data point pairs to extract the features from. We suggest constructing the pairs in the following way:\n",
    "1. Let's say our time points are indexed as $t^{(1)}, t^{(2)}, t^{(3)}, ..., t^{(m)}$.\n",
    "2. Take a subsequence of every 3rd point, starting from the first index, like $t^{(1)}, t^{(4)}, t^{(7)}, ... $.\n",
    "3. Repeat step 2 for different starting indices until every data point falls in exactly one subsequence.\n",
    "4. Repeat steps 2 and 3, but this time take every 5th point. Repeat it for every 7th point as well.\n",
    "5. Adjacent points in each subsequence will now be valid pairs.\n",
    "\n",
    "**Make sure data point pairs are such that the motor has the same phase in both data points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd656faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {% if exercise['3.1.2'].solution %}\n",
    "@dataclass(frozen=True)\n",
    "class DataForPhase:\n",
    "    t: Vector\n",
    "    T: Vector\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataForPhases:\n",
    "    on: DataForPhase\n",
    "    off: DataForPhase\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataSequences:\n",
    "    t: list[Vector]\n",
    "    T: list[Vector]\n",
    "    on_sequence_lengths: list[int]\n",
    "    off_sequence_lengths: list[int]\n",
    "\n",
    "    def initial_temperatures(self) -> Vector:\n",
    "        # Since the running times are for calculated from subsequent pairs of time points,\n",
    "        # we just need to remove the last element from each temperature sequence.\n",
    "        return np.concatenate([sequence[:-1] for sequence in self.T])\n",
    "\n",
    "    def running_times(self) -> Vector:\n",
    "        return np.concatenate([np.diff(sequence) for sequence in self.t])\n",
    "\n",
    "    def temperature_differences(self) -> Vector:\n",
    "        return np.concatenate([np.diff(sequence) for sequence in self.T])\n",
    "\n",
    "    def motor_phases(self) -> Vector:\n",
    "        # We encode the motor phase (on = 1, off = 0). We also shouldn't forget the -1,\n",
    "        # since we are dropping one element from each sequence when calculating the running times.\n",
    "        phase_on = [np.ones(length - 1) for length in self.on_sequence_lengths]\n",
    "        phase_off = [np.zeros(length - 1) for length in self.off_sequence_lengths]\n",
    "\n",
    "        return np.concatenate([*phase_on, *phase_off])\n",
    "\n",
    "\n",
    "def split_into_phases(t: Vector, T: Vector) -> DataForPhases:\n",
    "    # This can be done by splitting the data right in the middle\n",
    "    # Generally the easiest way is to just look at the data.\n",
    "    t_mid = t[len(t) // 2]\n",
    "    t_on, t_off = t[t < t_mid], t[t >= t_mid]\n",
    "    T_on, T_off = T[t < t_mid], T[t >= t_mid]\n",
    "\n",
    "    return DataForPhases(\n",
    "        on=DataForPhase(t=t_on, T=T_on), off=DataForPhase(t=t_off, T=T_off)\n",
    "    )\n",
    "\n",
    "\n",
    "def create_sequences(data: DataForPhases) -> DataSequences:\n",
    "    # The way we do it is kind of arbitrary, but it's a good starting point.\n",
    "    def sequences_from(x: Vector) -> list[Vector]:\n",
    "        return [x[i::j] for j in [3, 5, 7] for i in range(j)]\n",
    "\n",
    "    t_on_sequences, t_off_sequences = (\n",
    "        sequences_from(data.on.t),\n",
    "        sequences_from(data.off.t),\n",
    "    )\n",
    "    T_on_sequences, T_off_sequences = (\n",
    "        sequences_from(data.on.T),\n",
    "        sequences_from(data.off.T),\n",
    "    )\n",
    "\n",
    "    return DataSequences(\n",
    "        t=[*t_on_sequences, *t_off_sequences],\n",
    "        T=[*T_on_sequences, *T_off_sequences],\n",
    "        on_sequence_lengths=[len(sequence) for sequence in t_on_sequences],\n",
    "        off_sequence_lengths=[len(sequence) for sequence in t_off_sequences],\n",
    "    )\n",
    "\n",
    "\n",
    "# {% endif %}\n",
    "\n",
    "\n",
    "def extract_features(t: Vector, T: Vector) -> tuple[Matrix, Vector]:\n",
    "    # {% if exercise['3.2.1'].solution %}\n",
    "    # TODO: Review me!\n",
    "    # We first start by splitting the data into two phases - motor on and motor off.\n",
    "    data = split_into_phases(t, T)\n",
    "\n",
    "    # Next, we extract sequences of data for each phase.\n",
    "    data_sequences = create_sequences(data)\n",
    "\n",
    "    # We can now extract the interesting features and labels.\n",
    "    x_1 = data_sequences.initial_temperatures()\n",
    "    x_2 = data_sequences.running_times()\n",
    "    x_3 = data_sequences.motor_phases()\n",
    "\n",
    "    X = np.column_stack([x_1, x_2, x_3])\n",
    "    y = data_sequences.temperature_differences()\n",
    "\n",
    "    return X, y\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cc8c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots(figures: list[Figure], figure_height: int = 300) -> Figure:\n",
    "    n = len(figures)\n",
    "\n",
    "    figure = make_subplots(rows=n, cols=1, shared_xaxes=True, vertical_spacing=0.05)\n",
    "\n",
    "    for i, sub_figure in enumerate(figures, 1):\n",
    "        for trace in sub_figure.data:\n",
    "            figure.add_trace(trace, row=i, col=1)\n",
    "\n",
    "        # Update y-axis title for each subplot\n",
    "        figure.update_yaxes(title_text=sub_figure.layout.yaxis.title.text, row=i, col=1)\n",
    "\n",
    "    # Update the overall figure layout\n",
    "    figure.update_layout(\n",
    "        height=figure_height * n,\n",
    "    )\n",
    "\n",
    "    # Update x-axis title (only for the bottom subplot)\n",
    "    figure.update_xaxes(title_text=figures[-1].layout.xaxis.title.text, row=n, col=1)\n",
    "\n",
    "    return figure\n",
    "\n",
    "\n",
    "def plot_features(X: Matrix, y: Vector) -> Figure:\n",
    "    indices = np.arange(len(X)) * 1.0\n",
    "\n",
    "    initial_temperature_figure = set_layout_for(\n",
    "        Figure(data=[line_scatter(x=indices, y=X[:, 0], name=\"Initial Temperature\")]),\n",
    "        x_title=\"Data Point Index\",\n",
    "        y_title=r\"$\\text{Temperature (} x_1 \\text{)}$\",\n",
    "    )\n",
    "\n",
    "    time_difference_figure = set_layout_for(\n",
    "        Figure(\n",
    "            data=[\n",
    "                line_scatter(\n",
    "                    x=indices, y=X[:, 1], name=\"Time Difference\", color=\"orange\"\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        x_title=\"Data Point Index\",\n",
    "        y_title=r\"$\\text{Time (} x_2 \\text{)}$\",\n",
    "    )\n",
    "\n",
    "    phase_figure = set_layout_for(\n",
    "        Figure(\n",
    "            data=[line_scatter(x=indices, y=X[:, 2], name=\"Motor Phase\", color=\"green\")]\n",
    "        ),\n",
    "        x_title=\"Data Point Index\",\n",
    "        y_title=r\"$\\text{On/Off (} x_3 \\text{)}$\",\n",
    "    )\n",
    "\n",
    "    temperature_difference_figure = set_layout_for(\n",
    "        Figure(\n",
    "            data=[dot_scatter(x=indices, y=y, name=\"Final Temperature\", color=\"red\")]\n",
    "        ),\n",
    "        x_title=\"Data Point Index\",\n",
    "        y_title=r\"$\\text{Temperature (} y \\text{)}$\",\n",
    "    )\n",
    "\n",
    "    subplots(\n",
    "        [\n",
    "            initial_temperature_figure,\n",
    "            time_difference_figure,\n",
    "            phase_figure,\n",
    "            temperature_difference_figure,\n",
    "        ]\n",
    "    ).show()\n",
    "\n",
    "\n",
    "def zero_plane(x: Vector, y: Vector) -> go.Surface:\n",
    "    X, Y = input_to_grid(np.column_stack([x, y]))\n",
    "    Z = np.zeros(X.shape)\n",
    "\n",
    "    return surface_scatter(X, Y, Z, name=\"Zero Plane\", color=\"black\", opacity=0.1)\n",
    "\n",
    "\n",
    "def plot_features_3d(\n",
    "    X: Matrix,\n",
    "    y: Vector,\n",
    "    *,\n",
    "    additional_traces: list[go.Scatter3d | go.Surface] = [],\n",
    ") -> None:\n",
    "    on_indices = X[:, 2] == 1\n",
    "\n",
    "    T_0 = X[:, 0]\n",
    "    d_t = X[:, 1]\n",
    "    d_T = y\n",
    "\n",
    "    set_3d_layout_for(\n",
    "        go.Figure(\n",
    "            data=[\n",
    "                dot_scatter_3d(\n",
    "                    x=T_0[on_indices],\n",
    "                    y=d_t[on_indices],\n",
    "                    z=d_T[on_indices],\n",
    "                    color=\"red\",\n",
    "                    name=\"Motor On\",\n",
    "                ),\n",
    "                dot_scatter_3d(\n",
    "                    x=T_0[~on_indices],\n",
    "                    y=d_t[~on_indices],\n",
    "                    z=d_T[~on_indices],\n",
    "                    color=\"blue\",\n",
    "                    name=\"Motor Off\",\n",
    "                ),\n",
    "                *additional_traces,\n",
    "                zero_plane(T_0, d_t),\n",
    "            ]\n",
    "        ),\n",
    "        title=\"Temperature Change vs. Initial Temperature and Running Time\",\n",
    "        x_title=\"Initial Temperature\",\n",
    "        y_title=\"Running Time\",\n",
    "        z_title=\"Temperature Change\",\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a952b6",
   "metadata": {},
   "source": [
    "Okay, let's see what our features look like:\n",
    "\n",
    "- $x_1$ should look like scaled down sections of the original data stacked next to each other.\n",
    "- $x_2$ is time differences between neighboring points and should have 3 distinct sections for each phase.  \n",
    "- $x_3$ should be 1 for the first half and 0 for the second.\n",
    "- $y$ should have sections similar to $x_2$, but this time it's temperature differences which slowly decrease within the same section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_features(t_denoised, T_denoised)\n",
    "plot_features(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4c004",
   "metadata": {},
   "source": [
    "We can also take a look at it in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_3d(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352d628",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.3\n",
    "\n",
    "Implement the normalization methods of the `Normalizer` class below, which take the features extracted from the previous exercise and \n",
    "normalize/denormalize them. Specifically:\n",
    "\n",
    "- `normalize_temperature` should normalize the starting temperature of the motor winding to the range $[0, 1]$.\n",
    "- `normalize_time` should normalize the running times of the motor to the range $[0, 1]$.\n",
    "- `normalize_temperature_difference` should normalize the temperature differences to the range $[-1, 1]$.\n",
    "- `denormalize_temperature` should denormalize the predicted temperature differences back to the original range.\n",
    "\n",
    "The statistical properties of the data (e.g. mean and standard deviation), should be calculated the first time normalization happens. All future\n",
    "normalizations/denormalizations should use the statistical properties of the data provided for the first time.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> You can use the `MinMaxScaler` and `MaxAbsScaler` from the `sklearn.preprocessing` module to normalize the data. For denormalization, you can \n",
    "> use the `inverse_transform` method of the scaler. You can use the `fit` method of the scaler to calculate and set the statistical properties\n",
    "> of a particular vector of data. These properties will be used every time you call `transform` afterwards.\n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3af33022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "\n",
    "# {% if exercise['3.1.3'].solution %}\n",
    "Scaler: TypeAlias = MinMaxScaler | MaxAbsScaler\n",
    "ScalerCreator: TypeAlias = Callable[[], Scaler]\n",
    "# {% endif %}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Normalizer:\n",
    "    # {% if exercise['3.1.3'].solution %}\n",
    "    # TODO: Review me!\n",
    "    temperature_scaler: Scaler | None = None\n",
    "    time_scaler: Scaler | None = None\n",
    "    temperature_difference_scaler: Scaler | None = None\n",
    "    # {% endif %}\n",
    "\n",
    "    def normalize_temperature(self, T: Vector) -> Vector:\n",
    "        # {% if exercise['3.1.3'].solution %}\n",
    "        # TODO: Review me!\n",
    "        self.temperature_scaler, result = self.transform_with(\n",
    "            self.temperature_scaler, T, MinMaxScaler\n",
    "        )\n",
    "        return result\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def normalize_time(self, t: Vector) -> Vector:\n",
    "        # {% if exercise['3.1.3'].solution %}\n",
    "        # TODO: Review me!\n",
    "        self.time_scaler, result = self.transform_with(\n",
    "            self.time_scaler, t, MinMaxScaler\n",
    "        )\n",
    "        return result\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def normalize_temperature_difference(self, d_T: Vector) -> Vector:\n",
    "        # {% if exercise['3.1.3'].solution %}\n",
    "        # TODO: Review me!\n",
    "        self.temperature_difference_scaler, result = self.transform_with(\n",
    "            self.temperature_difference_scaler, d_T, MaxAbsScaler\n",
    "        )\n",
    "        return result\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def denormalize_temperature_difference(self, T: Vector) -> Vector:\n",
    "        # {% if exercise['3.1.3'].solution %}\n",
    "        # TODO: Review me!\n",
    "        assert (\n",
    "            self.temperature_difference_scaler is not None\n",
    "        ), \"Cannot denormalize data without normalizing some data first.\"\n",
    "\n",
    "        return self.temperature_difference_scaler.inverse_transform(\n",
    "            T.reshape(-1, 1)\n",
    "        ).flatten()\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    # {% if exercise['3.1.3'].solution %}\n",
    "\n",
    "    def transform_with(\n",
    "        self, scaler: Scaler | None, data: Vector, create_scaler: ScalerCreator\n",
    "    ) -> tuple[Scaler, Vector]:\n",
    "        reshaped_data = data.reshape(-1, 1)\n",
    "\n",
    "        if scaler is None:\n",
    "            scaler = create_scaler()\n",
    "            scaler.fit(reshaped_data)\n",
    "\n",
    "        return scaler, scaler.transform(reshaped_data).flatten()\n",
    "\n",
    "    # {% endif %}\n",
    "\n",
    "    def normalize(self, X: Matrix, y: Vector) -> tuple[Matrix, Vector]:\n",
    "        X = self.normalize_input(X)\n",
    "        y = self.normalize_temperature_difference(y)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def normalize_input(self, X: Matrix) -> Vector:\n",
    "        return np.column_stack(\n",
    "            [\n",
    "                self.normalize_temperature(X[:, 0]),\n",
    "                self.normalize_time(X[:, 1]),\n",
    "                X[:, 2],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def denormalize(self, y: Vector) -> Vector:\n",
    "        return self.denormalize_temperature_difference(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc747b",
   "metadata": {},
   "source": [
    "Our normalized data now looks like this (notice the scales have changed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eeea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "X_normalized, y_normalized = normalizer.normalize(X, y)\n",
    "plot_features(X_normalized, y_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a214c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_3d(X_normalized, y_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80fd9f",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.4\n",
    "\n",
    "Now we can shuffle and split the data into training and test sets. Implement the `split_data` function below, which takes the normalized features\n",
    "`X` and the output data `y`, shuffles them, and splits them into training and test sets. The function should return the training and test sets\n",
    "for both the features and the output data.\n",
    "\n",
    "The training set can be the first 75% of the data, and the test set can be the rest. A random seed is provided which you can use for reproducibility.\n",
    "\n",
    "<details>\n",
    "    <summary> Hint </summary>\n",
    "\n",
    "> &nbsp;  \n",
    "> You can use the `shuffle` and `train_test_split` functions from the `sklearn.model_selection` module to shuffle and split the data.  \n",
    "> &nbsp;\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acad9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataSet:\n",
    "    X: Matrix\n",
    "    y: Vector\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataSets:\n",
    "    training: DataSet\n",
    "    test: DataSet\n",
    "\n",
    "    def training_data(self) -> TrainingData:\n",
    "        return TrainingData(x=self.training.X, y=self.training.y)\n",
    "\n",
    "\n",
    "def split_data(X: Matrix, y: Vector, *, seed: int = 42) -> DataSets:\n",
    "    # {% if exercise['3.1.4'].solution %}\n",
    "    # TODO: Review me!\n",
    "    # We first shuffle the data\n",
    "    X, y = shuffle(X, y, random_state=seed)  # type: ignore\n",
    "\n",
    "    # Then we split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=seed\n",
    "    )\n",
    "\n",
    "    return DataSets(\n",
    "        training=DataSet(X=X_train, y=y_train),\n",
    "        test=DataSet(X=X_test, y=y_test),\n",
    "    )\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c04b5",
   "metadata": {},
   "source": [
    "Let's make sure we didn't mess up the data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = split_data(X_normalized, y_normalized)\n",
    "\n",
    "print(\"This is what the training data looks like:\")\n",
    "plot_features_3d(data_sets.training.X, data_sets.training.y)\n",
    "\n",
    "print(\"This is what the test data looks like:\")\n",
    "plot_features_3d(data_sets.test.X, data_sets.test.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1e56b",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.5\n",
    "\n",
    "Now create a multi-dimensional GPR model using the `MultiDimensionalGPRCreator` class and the training data. You can use the RBF kernel for each\n",
    "dimension. Make sure to also tune the hyperparameters of the kernel using the `optimize_hyperparameters` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {% if exercise['3.1.5'].solution %}\n",
    "# TODO: Review me!\n",
    "sigma_noise = 0.25\n",
    "model_creator = MultiDimensionalGPRCreator(data_sets.training_data(), sigma_noise)\n",
    "\n",
    "# We have three features, so we need six hyperparameters (sigma, l for each feature)\n",
    "theta_0 = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "theta = optimize_hyperparameters(\n",
    "    model_creator,\n",
    "    theta_0,\n",
    "    bounds=[(0.01, None)] * 6,\n",
    ")\n",
    "\n",
    "model = model_creator(theta)\n",
    "# {% else %}\n",
    "# TODO: Implement me!\n",
    "print(\"Oops! Looks like you forgot to implement this cell.\")\n",
    "# {% endif %}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742422cc",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.6\n",
    "\n",
    "Evaluate the performance of the GPR model on the test data. Implement the `evaluate` function below, which takes the GPR model and the test data,\n",
    "and returns the mean squared error (MSE) of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "681eb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: GPR, X: Matrix, y: Vector) -> float:\n",
    "    # {% if exercise['3.1.6'].solution %}\n",
    "    # TODO: Review me!\n",
    "    result = model.predict(X)\n",
    "\n",
    "    return float(np.mean((result.mean - y) ** 2))\n",
    "    # {% else %}\n",
    "    # TODO: Implement me!\n",
    "    raise NotImplementedError(\"Not implemented!\")\n",
    "    # {% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be927dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"MSE on the training data: {evaluate(model, data_sets.training.X, data_sets.training.y):.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"MSE on the test data: {evaluate(model, data_sets.test.X, data_sets.test.y):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10343c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_3d(\n",
    "    data_sets.test.X,\n",
    "    data_sets.test.y,\n",
    "    additional_traces=[\n",
    "        dot_scatter_3d(\n",
    "            x=data_sets.test.X[:, 0],\n",
    "            y=data_sets.test.X[:, 1],\n",
    "            z=model.predict(data_sets.test.X).mean,\n",
    "            name=\"Prediction\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bd7cc",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.7\n",
    "\n",
    "Finally, we can use our GPR model to predict the temperature of the motor winding at any given time. Implement the `predict` method of the\n",
    "`GPRTemperaturePredictor` class below, which takes a time `t`, a boolean parameter `on` (whether the motor is on or off) and returns the predicted\n",
    "temperature of the motor winding at the given time.\n",
    "\n",
    "In addition, store the most recent time and temperature of the motor winding in the `T_last` and `t_last` attributes of the class. You will need these\n",
    "to accurately predict the temperature of the next time step. In addition, keep even older time and temperature values in the `T_rollback` and `t_rollback`\n",
    "attributes. These will be used to roll back and re-predict the temperature in case the controller changes its decision about the appropriate motor phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05665c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPRTemperaturePredictor:\n",
    "    normalizer: Normalizer\n",
    "    model: GPR\n",
    "    T_0: float\n",
    "\n",
    "    T_last: float = 0.0\n",
    "    t_last: float = 0.0\n",
    "\n",
    "    T_rollback: float = 0.0\n",
    "    t_rollback: float = 0.0\n",
    "\n",
    "    def predict(self, t: float, on: bool) -> float:\n",
    "        # {% if exercise['3.1.7'].solution %}\n",
    "        # TODO: Review me!\n",
    "        x = np.array([[self.T_last, t - self.t_last, float(on)]])\n",
    "\n",
    "        # We first normalize the data\n",
    "        x_normalized = self.normalizer.normalize_input(x)\n",
    "\n",
    "        # We then predict the temperature difference\n",
    "        y_normalized = self.model.predict(x_normalized).mean\n",
    "\n",
    "        # Finally, we denormalize the prediction\n",
    "        y = self.normalizer.denormalize(y_normalized)[0]\n",
    "\n",
    "        # We back up the last prediction\n",
    "        self.T_rollback = self.T_last\n",
    "        self.t_rollback = self.t_last\n",
    "\n",
    "        # We store the new prediction\n",
    "        self.T_last = y + self.T_last\n",
    "        self.t_last = t\n",
    "\n",
    "        return y + self.T_last\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def rollback(self) -> None:\n",
    "        self.T_last = self.T_rollback\n",
    "        self.t_last = self.t_rollback\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.T_last = self.T_0\n",
    "        self.t_last = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6556cd4",
   "metadata": {},
   "source": [
    "Let's see what happens if we turn the motor on for some time and then turn it off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "033c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_original, T_original = extract_data_from(temperature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed3610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = GPRTemperaturePredictor(normalizer, model, T_0=25.0)\n",
    "predictor.reset()\n",
    "\n",
    "t = np.linspace(0, 300, 50)\n",
    "T = np.array([predictor.predict(t_i, on=(t_i < 150)) for t_i in t])\n",
    "\n",
    "set_layout_for(\n",
    "    Figure(\n",
    "        data=[\n",
    "            line_scatter(x=t, y=T, name=\"Predicted Temperature\"),\n",
    "            dot_scatter(x=t_original, y=T_original, name=\"Original Temperature\"),\n",
    "        ]\n",
    "    ),\n",
    "    title=\"Predicted temperature of the motor\",\n",
    "    x_title=\"Time\",\n",
    "    y_title=\"Temperature\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e94f4f",
   "metadata": {},
   "source": [
    "If all went well, the predicted temperature plot should be very close to the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff248a",
   "metadata": {},
   "source": [
    "### 3.2. Creating the Controller\n",
    "\n",
    "Now that we have a model that can predict the temperature of the motor winding, we can use it to create a controller that regulates the motor activity.\n",
    "\n",
    "#### Exercise 3.2.1\n",
    "\n",
    "Implement the `BangBangController` class below, which takes a `TemperaturePredictor` and temperature `thresholds`. The controller's `control` method\n",
    "takes a time `t` and returns `True` if the motor should be turned on at that time, and `False` otherwise.\n",
    "\n",
    "The controller logic can be as follows:\n",
    "- If the predicted temperature is above (overheating) `thresholds.upper`, the motor must be turned off.\n",
    "- If a motor was recently turned off, and the predicted temperature is below (cool down) `thresholds.lower`, the motor should be turned on again.\n",
    "\n",
    "Since the `TemperaturePredictor` relies on previous time steps to make predictions, make sure to use the `rollback` method of the `TemperaturePredictor`\n",
    "to update the temperature prediction whenever the controller changes its decision.\n",
    "\n",
    "For example, if you predict the temperature at time $t$ for the motor being on, and then decide it's better to turn it off (also at time $t$), you should\n",
    "roll back the prediction and re-predict the temperature at time $t$ for the motor being off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba7059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemperaturePredictor(Protocol):\n",
    "    def predict(self, t: float, on: bool) -> float:\n",
    "        \"\"\"Predicts the temperature of the motor at time `t`, considering if the motor is on or off.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def rollback(self) -> None:\n",
    "        \"\"\"Rolls back the most recent prediction.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the predictor to its initial state.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2f352ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ControlDecision:\n",
    "    on: bool\n",
    "    t_start: float\n",
    "    t_end: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BangBangController:\n",
    "    predictor: TemperaturePredictor\n",
    "    thresholds: TemperatureThresholds\n",
    "    cache: list[ControlDecision] = field(default_factory=list)\n",
    "\n",
    "    # {% if exercise['3.2.1'].solution %}\n",
    "    on: bool = False\n",
    "    # {% endif %}\n",
    "\n",
    "    def control(self, t: float) -> bool:\n",
    "        # {% if exercise['3.2.1'].solution %}\n",
    "        # TODO: Review me!\n",
    "        temperature = self.predictor.predict(t, on=self.on)\n",
    "\n",
    "        if temperature > self.thresholds.upper and self.on:\n",
    "            self.on = False\n",
    "            self.predictor.rollback()\n",
    "            self.predictor.predict(t, on=self.on)\n",
    "        elif temperature < self.thresholds.lower and not self.on:\n",
    "            self.on = True\n",
    "            self.predictor.rollback()\n",
    "            self.predictor.predict(t, on=self.on)\n",
    "\n",
    "        return self.on\n",
    "        # {% else %}\n",
    "        # TODO: Implement me!\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # {% endif %}\n",
    "\n",
    "    def in_cache(self, t: float) -> bool:\n",
    "        return any(decision.t_start <= t <= decision.t_end for decision in self.cache)\n",
    "\n",
    "    def from_cache(self, t: float) -> ControlDecision:\n",
    "        return next(\n",
    "            decision\n",
    "            for decision in self.cache\n",
    "            if decision.t_start <= t <= decision.t_end\n",
    "        )\n",
    "\n",
    "    def add_to_cache(self, on: bool, t_end: float) -> None:\n",
    "        if len(self.cache) == 0:\n",
    "            t_start = 0.0\n",
    "        else:\n",
    "            t_start = self.cache[-1].t_end\n",
    "\n",
    "        self.cache.append(ControlDecision(on=on, t_start=t_start, t_end=t_end))\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        if self.in_cache(t):\n",
    "            return self.from_cache(t).on\n",
    "\n",
    "        on = self.control(t)\n",
    "        self.add_to_cache(on, t)\n",
    "\n",
    "        return 1.0 if on else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e039f",
   "metadata": {},
   "source": [
    "The final test! Let's see if our controller can regulate the motor activity based on the predicted temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a52298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TemperaturePredictionsCache:\n",
    "    predictor: TemperaturePredictor\n",
    "    cache: dict[float, float] = field(default_factory=dict)\n",
    "\n",
    "    def predict(self, t: float, on: bool) -> float:\n",
    "        self.cache[t] = self.predictor.predict(t, on)\n",
    "        return self.cache[t]\n",
    "\n",
    "    def rollback(self) -> None:\n",
    "        self.predictor.rollback()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.predictor.reset()\n",
    "        self.cache.clear()\n",
    "\n",
    "    def __call__(self, t: float) -> float:\n",
    "        assert t in self.cache, f\"Temperature at time {t} has not been predicted yet.\"\n",
    "        return self.cache[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce01dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cache the predictions to avoid recalculating them when visualizing the controller.\n",
    "predictions_cache = TemperaturePredictionsCache(predictor)\n",
    "thresholds = TemperatureThresholds(lower=27, upper=28)\n",
    "controller = BangBangController(predictions_cache, thresholds)\n",
    "\n",
    "# Bang-bang controller with GPR predictor.\n",
    "u: ControlSignal = controller\n",
    "T_L: Load = lambda _: 0  # Doesn't matter for temperature prediction\n",
    "\n",
    "morton = (\n",
    "    Motor(\"Morton\")\n",
    "    .with_control_signal(u)\n",
    "    .with_load(T_L)\n",
    "    .with_dynamics(motor_dynamics(J=1.0, B=0.1, K_T=1.0, u=u, T_L=T_L))\n",
    "    .with_predicted_temperature(predictions_cache)\n",
    ")\n",
    "\n",
    "# Let's not forget to check what the temperature really looks like.\n",
    "morton = morton.with_temperature(TemperatureSensor.for_motor(morton))\n",
    "\n",
    "# The simulation is even longer\n",
    "morton.animate(t_f=600.0, steps=100, thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa9b69",
   "metadata": {},
   "source": [
    "### 3.3. Reflection\n",
    "\n",
    "- How well did the GPR model predict the temperature of the motor winding? Did the motor overheat or cool down too much?\n",
    "- What would happen if the simulation went on for a longer time? Would the predictions be more accurate?\n",
    "- Do the size of the time steps affect the accuracy of the predictions? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31d2352",
   "metadata": {},
   "source": [
    "Well done! You've successfully created a controller that can regulate the motor activity based on the predicted temperature of the motor winding. It's\n",
    "pretty cool to see that it actually works, right? Although, it's probably not the best way to design such a controller, you at least hopefully learned a\n",
    "lot about Gaussian Process Regression and *some* of its applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
