{"class_name": "Tokenizer", "config": {"num_words": null, "filters": null, "lower": false, "split": " ", "char_level": false, "oov_token": null, "document_count": 2696802, "word_counts": "{\"O\": 2019178, \"ORG\": 251913, \"LOC\": 180990, \"PER\": 244721}", "word_docs": "{\"O\": 2019178, \"ORG\": 251913, \"LOC\": 180990, \"PER\": 244721}", "index_docs": "{\"1\": 2019178, \"2\": 251913, \"4\": 180990, \"3\": 244721}", "index_word": "{\"1\": \"O\", \"2\": \"ORG\", \"3\": \"PER\", \"4\": \"LOC\"}", "word_index": "{\"O\": 1, \"ORG\": 2, \"PER\": 3, \"LOC\": 4}"}}