"""
How to guides
===============

"""


######################################################################
# Introduction
# ------------
#
# To run this tutorial, you need to load the AiiDA profile.
#

from aiida import load_profile

load_profile()


######################################################################
# Default outputs
# --------------
#
# The default output of the function is `result`. The `PythonJob` task
# will store the result as one node in the database with the key `result`.
#
from aiida.engine import run_get_node  # noqa: E402
from aiida_pythonjob import PythonJob, prepare_pythonjob_inputs  # noqa: E402


def add(x, y):
    return x + y


inputs = prepare_pythonjob_inputs(
    add,
    function_inputs={"x": 1, "y": 2},
    computer="localhost",
)
result, node = run_get_node(PythonJob, inputs=inputs)
print("result: ", result["result"])

######################################################################
# Custom outputs
# --------------
# If the function return a dictionary with fixed number of keys, and you
# want to store the values as separate outputs, you can specify the `function_outputs` parameter.
# For a dynamic number of outputs, you can use the namespace output, which is explained later.
#


def add(x, y):
    return {"sum": x + y, "diff": x - y}


inputs = prepare_pythonjob_inputs(
    add,
    function_inputs={"x": 1, "y": 2},
    function_outputs=[
        {"name": "sum"},
        {"name": "diff"},
    ],
)
result, node = run_get_node(PythonJob, **inputs)

print("result: ")
print("sum: ", result["sum"])
print("diff: ", result["diff"])


######################################################################
# Using parent folder
# --------------
# The parent_folder parameter allows a task to access the output files of
# a parent task. This feature is particularly useful when you want to reuse
# data generated by a previous computation in subsequent computations. In
# the following example, the multiply task uses the `result.txt` file created by the add task.
#
#


def add(x, y):
    z = x + y
    with open("result.txt", "w") as f:
        f.write(str(z))
    return x + y


def multiply(x, y):
    with open("parent_folder/result.txt", "r") as f:
        z = int(f.read())
    return x * y + z


inputs1 = prepare_pythonjob_inputs(
    add,
    function_inputs={"x": 1, "y": 2},
    function_outputs=[{"name": "sum"}],
)

result1, node1 = run_get_node(PythonJob, inputs=inputs1)

inputs2 = prepare_pythonjob_inputs(
    multiply,
    function_inputs={"x": 1, "y": 2},
    function_outputs=[{"name": "product"}],
    parent_folder=result1["remote_folder"],
)

result2, node2 = run_get_node(PythonJob, inputs=inputs2)

print("result: ", result2)

######################################################################
# Upload files or folders to the remote computer
# --------------
# The `upload_files` parameter allows users to upload files or folders to
# the remote computer. The files will be uploaded to the working directory of the remote computer.
#

import os  # noqa: E402

# create a temporary file "input.txt" in the current directory
with open("/tmp/input.txt", "w") as f:
    f.write("2")

# create a temporary folder "inputs_folder" in the current directory
# and add a file "another_input.txt" in the folder
os.makedirs("/tmp/inputs_folder", exist_ok=True)
with open("/tmp/inputs_folder/another_input.txt", "w") as f:
    f.write("3")


def add():
    with open("input.txt", "r") as f:
        a = int(f.read())
    with open("inputs_folder/another_input.txt", "r") as f:
        b = int(f.read())
    return a + b


# ------------------------- Submit the calculation -------------------
# we need use full path to the file
input_file = os.path.abspath("/tmp/input.txt")
input_folder = os.path.abspath("/tmp/inputs_folder")
inputs = prepare_pythonjob_inputs(
    add,
    upload_files={
        "input.txt": input_file,
        "inputs_folder": input_folder,
    },
)
result, node = run_get_node(PythonJob, inputs=inputs)
print("result: ", result["result"])

######################################################################
# Retrieve additional files from the remote computer
# --------------
# Sometimes, one may want to retrieve additional files from the remote
# computer after the job has finished. For example, one may want to retrieve
# the output files generated by the `pw.x` calculation in Quantum ESPRESSO.
#
# One can use the `additional_retrieve_list` parameter to specify which files
# should be retrieved from the working directory and stored in the local
# repository after the job has finished
#


def add(x, y):
    z = x + y
    with open("result.txt", "w") as f:
        f.write(str(z))
    return x + y


inputs = prepare_pythonjob_inputs(
    add,
    function_inputs={"x": 1, "y": 2},
    metadata={
        "options": {
            "additional_retrieve_list": ["result.txt"],
        }
    },
)

result, node = run_get_node(PythonJob, inputs=inputs)
print("retrieved files: ", result["retrieved"].list_object_names())

######################################################################
# Namespace Output
# --------------
#
# The `PythonJob` allows users to define namespace outputs. A namespace output
# is a dictionary with keys and values returned by a function. Each value in
# this dictionary will be serialized to AiiDA data, and the key-value pair
# will be stored in the database.
# Why Use Namespace Outputs?
#
# - **Dynamic and Flexible**: The keys and values in the namespace output are
# not fixed and can change based on the task's execution.
# - **Querying**: The data in the namespace output is stored as an AiiDA data
# node, allowing for easy querying and retrieval.
# - **Data Provenance**: When the data is used as input for subsequent tasks,
# the origin of data is tracked.
#
# For example: Consider a molecule adsorption calculation where the namespace
# output stores the surface slabs of the molecule adsorbed on different surface
# sites. The number of surface slabs can vary depending on the surface. These
# output surface slabs can be utilized as input to the next task to calculate the energy.

from ase import Atoms  # noqa: E402
from ase.build import bulk  # noqa: E402


def generate_structures(structure: Atoms, factor_lst: list) -> dict:
    """Scale the structure by the given factor_lst."""
    scaled_structures = {}
    for i in range(len(factor_lst)):
        atoms = structure.copy()
        atoms.set_cell(atoms.cell * factor_lst[i], scale_atoms=True)
        scaled_structures[f"s_{i}"] = atoms
    return {"scaled_structures": scaled_structures}


inputs = prepare_pythonjob_inputs(
    generate_structures,
    function_inputs={"structure": bulk("Al"), "factor_lst": [0.95, 1.0, 1.05]},
    function_outputs=[{"name": "scaled_structures", "identifier": "namespace"}],
)

result, node = run_get_node(PythonJob, inputs=inputs)
print("scaled_structures: ")
for key, value in result["scaled_structures"].items():
    print(key, value)

######################################################################
# Exit Code
# --------------
#
#
# When the function returns a dictionary with an `exit_code` key, the system
# automatically parses and uses this code to indicate the task's status. In
# the case of an error, the non-zero `exit_code` value helps identify the specific problem.
#
#


def add(x, y):
    sum = x + y
    if (sum < 0).any():
        exit_code = {"status": 410, "message": "Some elements are negative"}
        return {"sum": sum, "exit_code": exit_code}
    return {"sum": sum}


inputs = prepare_pythonjob_inputs(
    add,
    function_inputs={"x": 1, "y": -21},
)

result, node = run_get_node(PythonJob, inputs=inputs)
print("exit_status:", node.exit_status)
print("exit_message:", node.exit_message)


######################################################################
# Define your data serializer
# --------------
#
# PythonJob search data serializer from the `aiida.data` entry point by the
# module name and class name (e.g., `ase.atoms.Atoms`).
#
# In order to let the PythonJob find the serializer, you must register the
# AiiDA data with the following format:
#
# .. code-block:: ini
#
#    [project.entry-points."aiida.data"]
#    abc.ase.atoms.Atoms = "abc.xyz:MyAtomsData"
#
# This will register a data serializer for `ase.atoms.Atoms` data. `abc` is
# the plugin name, the module name is `xyz`, and the AiiDA data class name is
# `AtomsData`. Learn how to create an AiiDA data class `here <https://aiida.readthedocs.io/projects/aiida-core/en/stable/topics/data_types.html#adding-support-for-custom-data-types>`_.
#
# *Avoid duplicate data serializer*: If you have multiple plugins that
# register the same data serializer, the PythonJob will raise an error.
# You can avoid this by selecting the plugin that you want to use in the configuration file.
#
#
# .. code-block:: json
#
#    {
#        "serializers": {
#            "ase.atoms.Atoms": "abc.ase.atoms.Atoms"
#        }
#    }
#
# Save the configuration file as `pythonjob.json` in the aiida configuration
# directory (by default, `~/.aiida` directory).


######################################################################
# What's Next
# -----------
# +-----------------------------------------+------------------------------------------------------+
# | `Tutorials <../tutorial/index.rst>`__   | Real-world examples in computational materials       |
# |                                         | science and more.                                    |
# |                                         |                                                      |
# +-----------------------------------------+------------------------------------------------------+
#
#
